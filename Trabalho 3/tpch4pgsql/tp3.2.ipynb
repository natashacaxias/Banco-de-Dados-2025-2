{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0cc7dd7",
   "metadata": {},
   "source": [
    "# Introdução à Banco de Dados | Trabalho Prático III\n",
    "Abel Severo Rocha, Ana Carla Fernandes, Natasha Caxias\n",
    "\n",
    "Prof. Dr. Altigran Soares da Silva"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61a0749",
   "metadata": {},
   "source": [
    "## Parte I\n",
    "Verificação dos parâmetros do hardware e do software utilizado e familiarização com o ambiente do PostgreSQL."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78568dea",
   "metadata": {},
   "source": [
    "### Tarefa 1 - Identificação do Sistema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ea43b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca6601b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "import time\n",
    "import random\n",
    "import threading\n",
    "import matplotlib.pyplot as plt\n",
    "import threading\n",
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "import datetime\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "from psycopg2.extras import RealDictCursor\n",
    "from tpch_pgsql import main as tpch_pgsql\n",
    "from tpch4pgsql import postgresqldb as pgdb, result as r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0d100a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostrarSoInfo():\n",
    "    \n",
    "    soInfo = platform.freedesktop_os_release()\n",
    "    print(\"\\n--------- Sistema Operacional (SO) ---------\\n\")\n",
    "    print(\"Sistema Operacional \", platform.system())\n",
    "    print(\"Versão              \", soInfo[\"VERSION\"])\n",
    "    print(\"Release (kernel)    \", platform.release())\n",
    "    print(\"Arquitetura         \", platform.machine())\n",
    "    print(\"Distribuição        \", soInfo[\"NAME\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fffed5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostrarHardwareInfo():\n",
    "\n",
    "    cpuInfo = {}\n",
    "    with open(\"/proc/cpuinfo\") as f:\n",
    "        for line in f:\n",
    "            if \":\" in line:\n",
    "                k, v = line.split(\":\", 1)\n",
    "                cpuInfo[k.strip()] = v.strip()\n",
    "    \n",
    "    ramInfo = {}\n",
    "    with open(\"/proc/meminfo\") as f:\n",
    "        for line in f:\n",
    "            k, v = line.split(\":\", 1)\n",
    "            ramInfo[k] = v.strip()\n",
    "\n",
    "    print(\"\\n------------- Sobre o Hardware -------------\\n\")\n",
    "    print(\"Processador:\")\n",
    "    print(\"  • Modelo          \", cpuInfo[\"model name\"])\n",
    "    print(\"  • CPUs lógicas    \", os.cpu_count())\n",
    "    print(\"  • Clock base      \", cpuInfo[\"cpu MHz\"], \"MHz\")\n",
    "\n",
    "    print(\"\\nCache:\")\n",
    "    with open(\"/sys/devices/system/cpu/cpu0/cache/index0/size\") as f:\n",
    "        print(\"  • L1d             \", f.read().strip()[:-1]+\" kB\")\n",
    "    with open(\"/sys/devices/system/cpu/cpu0/cache/index1/size\") as f:\n",
    "        print(\"  • L1i             \", f.read().strip()[:-1]+\" kB\")\n",
    "    with open(\"/sys/devices/system/cpu/cpu0/cache/index2/size\") as f:\n",
    "        print(\"  • L2              \", f.read().strip()[:-1]+\" kB\")\n",
    "    with open(\"/sys/devices/system/cpu/cpu0/cache/index3/size\") as f:\n",
    "        print(\"  • L3              \", f.read().strip()[:-1]+\" kB\")\n",
    "\n",
    "    print(\"\\nMemória RAM:\")\n",
    "    print(\"  • Total           \", ramInfo[\"MemTotal\"])\n",
    "    print(\"  • Livre           \", ramInfo[\"MemFree\"])\n",
    "    print(\"  • Disponível      \", ramInfo[\"MemAvailable\"])\n",
    "\n",
    "    total, usado, livre = shutil.disk_usage(\"/\")\n",
    "    print(\"\\nDisco:\")\n",
    "    print(f\"  • Total            {total/1024**3:.2f} GB\")\n",
    "    print(f\"  • Usado            {usado/1024**3:.2f} GB\")\n",
    "    print(f\"  • Livre            {livre/1024**3:.2f} GB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fa38fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrarSoInfo()\n",
    "mostrarHardwareInfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777d7b9b",
   "metadata": {},
   "source": [
    "### Tarefa 2 - Verificação de parâmetros de armazenamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4741aa14",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = \"/sys/block\"\n",
    "\n",
    "def run(cmd):\n",
    "    return subprocess.check_output(cmd, text=True).strip()\n",
    "\n",
    "def getDispositivo():\n",
    "    for dev in os.listdir(BASE):\n",
    "        if dev.startswith((\"loop\", \"ram\", \"dm-\")): # ignora\n",
    "            continue\n",
    "        return dev # encontra dispositivo\n",
    "    return None\n",
    "\n",
    "def ehHD(dispositivo):\n",
    "    rotational_path = os.path.join(BASE, dispositivo, \"queue/rotational\")\n",
    "    \n",
    "    if os.path.exists(rotational_path):\n",
    "        with open(rotational_path) as f:\n",
    "            return f.read().strip() == \"1\"\n",
    "    return False\n",
    "\n",
    "def blocos(dispositivo):\n",
    "    cmd = f\"cat /sys/block/{dispositivo}/queue/logical_block_size\"\n",
    "    print(\"Blocos Lógicos        \", run(cmd.split()))\n",
    "\n",
    "    cmd = f\"cat /sys/block/{dispositivo}/queue/physical_block_size\"\n",
    "    print(\"Blcocos Físicos       \", run(cmd.split()))\n",
    "\n",
    "def stat(dispositivo):\n",
    "    cmd = f\"stat -f /dev/{dispositivo}\"\n",
    "    print(\"\\nParâmetros do SO para o disco (stat):\")\n",
    "    print(run(cmd.split()))\n",
    "\n",
    "def mostrarDiscoInfo():\n",
    "    disp = getDispositivo()\n",
    "    print(\"Tipos de dispositivo  \", \"HD\" if ehHD(disp) else \"SSD\")\n",
    "    cmd = [\"cat\", f\"/sys/block/{disp}/device/model\"]\n",
    "    print(\"Modelo                \", run(cmd))\n",
    "    stat(disp)\n",
    "    print()\n",
    "    blocos(disp)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be8daa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrarDiscoInfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca523d1",
   "metadata": {},
   "source": [
    "#### Como alterar tamanho dos blocos\n",
    "\n",
    "Só é possível alterar o tamanho dos blocos **recriando o sistema de arquivos** com o comando \n",
    "\n",
    "``sudo mkfs.ext4 -b [tamanho do bloco] /dev/sdXN``"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75fe921",
   "metadata": {},
   "source": [
    "#### Espeficiações do modelo\n",
    "\n",
    "##### Performance\n",
    "\n",
    "- Sequential Read\t    7,000 MB/s\n",
    "- Sequential Write\t4,700 MB/s\n",
    "- Random Read  \t    960,000 IOPS\n",
    "- Random Write\t    1,000,000 IOPS\n",
    "- Endurance       \t300 TBW\n",
    "- MTBF            \t1.5 Million Hours\n",
    "- Drive Writes Per Day (DWPD)\t0.3\n",
    "- SLC Write Cache \tYes\n",
    "- Speed when Cache Exhausted\tapprox. 770 MB/s\n",
    "\n",
    "Mais informações: [Link](https://www.techpowerup.com/ssd-specs/sk-hynix-pc801-512-gb.d2297)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969797c6",
   "metadata": {},
   "source": [
    "### Tarefa 3 – Geração de um BD para testes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3051d2",
   "metadata": {},
   "source": [
    "\n",
    "Necessário dar permissão de escrita. Abra o terminal e execute o seguinte comando:\n",
    "\n",
    "``chmod -R u+rwX,g+rwX,o+rX .``"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fe2249",
   "metadata": {},
   "source": [
    "#### Preparar\n",
    "A fase de preparação compila o TPC-H dbgen e querygen e cria os arquivos de carga e atualização (atualização/exclusão)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad2b32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tpch_pgsql(phase=\"prepare\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f267c36",
   "metadata": {},
   "source": [
    "#### Carregamento\n",
    "\n",
    "A fase de carregamento (load) limpa o banco de dados (se necessário), carrega as tabelas no banco de dados e cria índices para consultas. Os resultados desta fase consistem nas seguintes métricas:\n",
    "\n",
    "* Tempo de criação do esquema\n",
    "* Tempo de carregamento dos dados\n",
    "* Tempo de criação de restrições de chave estrangeira e índices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd988054",
   "metadata": {},
   "outputs": [],
   "source": [
    "tpch_pgsql(phase=\"load\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f2707b",
   "metadata": {},
   "source": [
    "#### Consultas\n",
    "\n",
    "Nessa fase, as consultas serão analizadas com o comando ``EXPLAIN ANALYZE``, evidenciando:\n",
    "\n",
    "* Tempo de execução do planejamento;\n",
    "* Tempo de execução do _exlpain_;\n",
    "* Algoritmos utilizados.\n",
    "\n",
    "Em seguida, as consultas serão executas, exibindo as seguintes informações:\n",
    "\n",
    "* Até 10 linhas do resultado da consulta;\n",
    "* Total de linhas encontradas;\n",
    "* Tempo de execução."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4fb597c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PGDBW(pgdb.PGDB):\n",
    "\n",
    "    def __init__(self, host, port, database, user, password):\n",
    "        # Chamar o construtor da classe pai corretamente\n",
    "        self.conn = psycopg2.connect(\n",
    "                    host=host,\n",
    "                    port=port,\n",
    "                    dbname=database,\n",
    "                    user=user,\n",
    "                    password=password\n",
    "                ) \n",
    "        if hasattr(self, 'conn') and self.conn:\n",
    "            print(\"Conexão estabelecida com sucesso!\")\n",
    "        else:\n",
    "            print(\"Atenção: Conexão não estabelecida\")\n",
    "    \n",
    "    def executeQueryFromFileWithResults(self, filepath):\n",
    "        \"\"\"Executa query de arquivo e retorna resultados\"\"\"\n",
    "        try:\n",
    "            # Verificar se a conexão existe\n",
    "            if not hasattr(self, 'conn') or not self.conn:\n",
    "                return {'error': 'Conexão não disponível'}\n",
    "            \n",
    "            with open(filepath, 'r') as f:\n",
    "                query = f.read()\n",
    "            \n",
    "            # Usar cursor que retorna dicionários\n",
    "            with self.conn.cursor(cursor_factory=RealDictCursor) as cursor:\n",
    "                cursor.execute(query)\n",
    "                \n",
    "                if cursor.description:  # Se é uma query SELECT\n",
    "                    results = cursor.fetchall()\n",
    "                    columns = [desc[0] for desc in cursor.description]\n",
    "                    return {\n",
    "                        'columns': columns,\n",
    "                        'data': results,\n",
    "                        'rowcount': cursor.rowcount\n",
    "                    }\n",
    "                else:  # Para INSERT, UPDATE, DELETE\n",
    "                    return {\n",
    "                        'rowcount': cursor.rowcount,\n",
    "                        'message': f\"Query executada: {cursor.rowcount} linhas afetadas\"\n",
    "                    }\n",
    "                    \n",
    "        except Exception as e:\n",
    "            return {'error': str(e)}\n",
    "        \n",
    "    def executeQuery(self, query_string):\n",
    "        \"\"\"Executa uma query diretamente a partir de string\"\"\"\n",
    "        try:\n",
    "            \n",
    "            with self.conn.cursor(cursor_factory=RealDictCursor) as cursor:\n",
    "                cursor.execute(query_string)\n",
    "                \n",
    "                if cursor.description:  # Se é uma query SELECT\n",
    "                    results = cursor.fetchall()\n",
    "                    columns = [desc[0] for desc in cursor.description]\n",
    "                    return {\n",
    "                        'columns': columns,\n",
    "                        'data': results,\n",
    "                        'rowcount': cursor.rowcount\n",
    "                    }\n",
    "                else:  # Para INSERT, UPDATE, DELETE\n",
    "                    self.conn.commit()\n",
    "                    return {\n",
    "                        'rowcount': cursor.rowcount,\n",
    "                        'message': f\"Query executada: {cursor.rowcount} linhas afetadas\"\n",
    "                    }\n",
    "                    \n",
    "        except Exception as e:\n",
    "            return {'error': str(e)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd991ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "host = \"localhost\"\n",
    "port = 5432\n",
    "user = \"icomp\"\n",
    "password = \"icomp123\"\n",
    "database = \"icomp\"\n",
    "filepath = \"query_root/perf_query_gen/\"\n",
    "\n",
    "conn = PGDBW(host, port, database, user, password)\n",
    "\n",
    "# Definir algoritmos de junção e varredura comuns no PostgreSQL\n",
    "algoritmos_juncao = ['Nested Loop', 'Hash Join', 'Merge Join']\n",
    "algoritmos_varredura = ['Seq Scan', 'Index Scan', 'Index Only Scan', 'Bitmap Heap Scan', 'Bitmap Index Scan']\n",
    "algoritmos_ordenacao = ['Sort', 'Incremental Sort']\n",
    "algoritmos_agregacao = ['HashAggregate', 'GroupAggregate']\n",
    "\n",
    "for i in [1, 3, 5, 6, 7, 9, 10, 12]:\n",
    "    print(f\"\\n{'=' * 120}\")\n",
    "    print(f\"EXPLAIN ANALYZE - QUERY {i}\")\n",
    "    print(f\"{'=' * 120}\")\n",
    "    \n",
    "    # Ler a query original\n",
    "    with open(filepath + f\"{i}.sql\", 'r') as f:\n",
    "        original_query = f.read()\n",
    "    \n",
    "    # Adicionar EXPLAIN ANALYZE\n",
    "    explain_query = \"EXPLAIN ANALYZE \" + original_query\n",
    "    \n",
    "    start_time = datetime.datetime.now()\n",
    "    result = conn.executeQuery(explain_query)\n",
    "    end_time = datetime.datetime.now()\n",
    "    execution_time = end_time - start_time\n",
    "    \n",
    "    if 'error' in result:\n",
    "        print(f\"Erro no EXPLAIN ANALYZE {i}: {result['error']}\")\n",
    "    elif 'data' in result:\n",
    "        print(f\"\\nTempo de execução do EXPLAIN: {execution_time}\")\n",
    "        \n",
    "        # Coletar algoritmos utilizados\n",
    "        algoritmos_encontrados = {\n",
    "            'juncao': [],\n",
    "            'varredura': [],\n",
    "            'ordenacao': [],\n",
    "            'agregacao': [],\n",
    "            'outros': []\n",
    "        }\n",
    "        \n",
    "        print(f\"\\nPLANO DE EXECUÇÃO (EXPLAIN ANALYZE):\")\n",
    "        for idx, row in enumerate(result['data']):\n",
    "            plan_line = list(row.values())[0] if row else \"\"\n",
    "            print(f\"{plan_line}\")\n",
    "            \n",
    "            # Identificar algoritmos na linha do plano\n",
    "            for algoritmo in algoritmos_juncao:\n",
    "                if algoritmo in plan_line:\n",
    "                    if algoritmo not in algoritmos_encontrados['juncao']:\n",
    "                        algoritmos_encontrados['juncao'].append(algoritmo)\n",
    "            \n",
    "            for algoritmo in algoritmos_varredura:\n",
    "                if algoritmo in plan_line:\n",
    "                    if algoritmo not in algoritmos_encontrados['varredura']:\n",
    "                        algoritmos_encontrados['varredura'].append(algoritmo)\n",
    "            \n",
    "            for algoritmo in algoritmos_ordenacao:\n",
    "                if algoritmo in plan_line:\n",
    "                    if algoritmo not in algoritmos_encontrados['ordenacao']:\n",
    "                        algoritmos_encontrados['ordenacao'].append(algoritmo)\n",
    "            \n",
    "            for algoritmo in algoritmos_agregacao:\n",
    "                if algoritmo in plan_line:\n",
    "                    if algoritmo not in algoritmos_encontrados['agregacao']:\n",
    "                        algoritmos_encontrados['agregacao'].append(algoritmo)\n",
    "        \n",
    "        # Mostrar resumo dos algoritmos utilizados\n",
    "        print(f\"\\n{'─' * 80}\")\n",
    "        print(\"ALGORITMOS IDENTIFICADOS NO PLANO DE EXECUÇÃO:\")\n",
    "        print(f\"{'─' * 80}\")\n",
    "        \n",
    "        if algoritmos_encontrados['juncao']:\n",
    "            print(f\"Algoritmos de Junção: {', '.join(algoritmos_encontrados['juncao'])}\")\n",
    "        \n",
    "        if algoritmos_encontrados['varredura']:\n",
    "            print(f\"Algoritmos de Varredura: {', '.join(algoritmos_encontrados['varredura'])}\")\n",
    "        \n",
    "        if algoritmos_encontrados['ordenacao']:\n",
    "            print(f\"Algoritmos de Ordenação: {', '.join(algoritmos_encontrados['ordenacao'])}\")\n",
    "        \n",
    "        if algoritmos_encontrados['agregacao']:\n",
    "            print(f\"Algoritmos de Agregação: {', '.join(algoritmos_encontrados['agregacao'])}\")\n",
    "        \n",
    "        # Verificar se não foram encontrados algoritmos conhecidos\n",
    "        total_algoritmos = (len(algoritmos_encontrados['juncao']) + \n",
    "                          len(algoritmos_encontrados['varredura']) + \n",
    "                          len(algoritmos_encontrados['ordenacao']) + \n",
    "                          len(algoritmos_encontrados['agregacao']))\n",
    "        \n",
    "        if total_algoritmos == 0:\n",
    "            print(\"ℹNenhum algoritmo específico identificado (possivelmente plano simples)\")\n",
    "            \n",
    "    else:\n",
    "        print(f\"{result.get('message', 'Resultado inesperado')}\")\n",
    "        print(f\"Tempo: {execution_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb66fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in [1, 3, 5, 6, 7, 9, 10, 12]:\n",
    "    print(f\"\\n{'=' * 120}\")\n",
    "    print(f\"QUERY {i}\")\n",
    "    print(f\"{'=' * 120}\")\n",
    "    \n",
    "    # Ler a query original\n",
    "    with open(filepath + f\"{i}.sql\", 'r') as f:\n",
    "        original_query = f.read()\n",
    "    \n",
    "    start_time = datetime.datetime.now()\n",
    "    result = conn.executeQuery(original_query)\n",
    "    end_time = datetime.datetime.now()\n",
    "    execution_time = end_time - start_time\n",
    "    \n",
    "    if 'error' in result:\n",
    "        print(f\"Erro ao executar query {i}: {result['error']}\")\n",
    "        continue\n",
    "    \n",
    "    if 'data' not in result or len(result['data']) == 0:\n",
    "        print(\"Nenhum dado retornado.\")\n",
    "        continue\n",
    "    \n",
    "    rows = result['data']\n",
    "    \n",
    "    # Pegar colunas (as chaves do primeiro registro)\n",
    "    headers = list(rows[0].keys())\n",
    "    \n",
    "    # Converter registros para lista de listas\n",
    "    table = [list(r.values()) for r in rows[:10]]\n",
    "    \n",
    "    print(tabulate(table, headers=headers, tablefmt=\"grid\"))\n",
    "    print(f\"Tempo de execução: {execution_time}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf60578d",
   "metadata": {},
   "source": [
    "## Parte II\n",
    "Análise do comportamento dos índices das tabelas do SGBD através do exame das tabelas de estatísticas para consultas SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39478c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuração de conexão para a PARTE II\n",
    "DB_CONFIG_PARTE2 = {\n",
    "    \"dbname\": \"icomp\",\n",
    "    \"user\": \"icomp\",\n",
    "    \"password\": \"icomp123\",   \n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": 5432\n",
    "}\n",
    "\n",
    "conn_p2 = psycopg2.connect(**DB_CONFIG_PARTE2)\n",
    "cur_p2 = conn_p2.cursor()\n",
    "print(\"Conectado ao PostgreSQL.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8355f1ab",
   "metadata": {},
   "source": [
    "### Tarefa 5 – Preparação da Tabela Aleatória\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c53abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_p2.execute(\"\"\"\n",
    "DROP TABLE IF EXISTS t;\n",
    "CREATE TABLE t (\n",
    "    k serial PRIMARY KEY,\n",
    "    v integer\n",
    ");\n",
    "\n",
    "INSERT INTO t(v)\n",
    "SELECT trunc(random() * 10)\n",
    "FROM generate_series(1,100000);\n",
    "\"\"\")\n",
    "conn_p2.commit()\n",
    "print(\"Tabela t criada e populada com 100.000 tuplas.\")\n",
    "\n",
    "cur_p2.execute(\"SELECT * FROM t ORDER BY k LIMIT 10;\")\n",
    "rows = cur_p2.fetchall()\n",
    "df_t10 = pd.DataFrame(rows, columns=[\"k\", \"v\"])\n",
    "print(\"\\nPrimeiras 10 tuplas da tabela t (ordenadas por k):\")\n",
    "print(df_t10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032afcdb",
   "metadata": {},
   "source": [
    "### Tarefa 6 – Páginas criadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd7976f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_p2.execute(\"\"\"\n",
    "SELECT relname, relpages, reltuples\n",
    "FROM pg_class\n",
    "WHERE relname = 't';\n",
    "\"\"\")\n",
    "rows = cur_p2.fetchall()\n",
    "df_pgclass = pd.DataFrame(rows, columns=[\"relname\", \"relpages\", \"reltuples\"])\n",
    "print(df_pgclass)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133dffae",
   "metadata": {},
   "source": [
    "### Tarefa 7 – Blocos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ca43d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_p2.execute(\"SELECT pg_sleep(1);\")\n",
    "\n",
    "cur_p2.execute(\"\"\"\n",
    "SELECT *\n",
    "FROM pg_stats\n",
    "WHERE tablename = 't';\n",
    "\"\"\")\n",
    "cols = [desc[0] for desc in cur_p2.description]\n",
    "df_pgstats = pd.DataFrame(cur_p2.fetchall(), columns=cols)\n",
    "\n",
    "print(\"\\nEstatísticas em pg_stats para tabela t:\")\n",
    "print(df_pgstats)\n",
    "\n",
    "cur_p2.execute(\"SELECT pg_stat_reset();\")\n",
    "conn_p2.commit()\n",
    "print(\"\\nEstatísticas resetadas com pg_stat_reset().\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ac05f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_io_stats(cur):\n",
    "    cur.execute(\"\"\"\n",
    "        SELECT\n",
    "            relname,\n",
    "            heap_blks_read,\n",
    "            heap_blks_hit,\n",
    "            idx_blks_read,\n",
    "            idx_blks_hit\n",
    "        FROM pg_statio_user_tables\n",
    "        WHERE relname = 't';\n",
    "    \"\"\")\n",
    "    row = cur.fetchone()\n",
    "    if row is None:\n",
    "        return None\n",
    "    cols = [d[0] for d in cur.description]\n",
    "    return dict(zip(cols, row))\n",
    "# Corrigir a transação falha anterior\n",
    "conn_p2.rollback()\n",
    "# 1) Estatísticas antes da consulta\n",
    "stats_before = get_io_stats(cur_p2)\n",
    "\n",
    "# 2) Rodar a consulta que você quer medir\n",
    "cur_p2.execute(\"SELECT pg_sleep(1);\")   # ou a consulta real em t\n",
    "conn.commit()\n",
    "\n",
    "# 3) Estatísticas depois da consulta\n",
    "stats_after = get_io_stats(cur_p2)\n",
    "\n",
    "print(\"Antes:\", stats_before)\n",
    "print(\"Depois:\", stats_after)\n",
    "\n",
    "if stats_before and stats_after:\n",
    "    delta = {\n",
    "        k: stats_after[k] - stats_before[k]\n",
    "        for k in [\"heap_blks_read\", \"heap_blks_hit\", \"idx_blks_read\", \"idx_blks_hit\"]\n",
    "    }\n",
    "    print(\"\\nBlocos efetivamente acessados pela consulta (diferença):\")\n",
    "    print(delta)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad6b99c",
   "metadata": {},
   "source": [
    "### Tarefa 8 – Índice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0627e950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Índice e consulta com 100k tuplas\n",
    "inicio = time.time()\n",
    "cur_p2.execute(\"CREATE INDEX idx_v ON t(v);\")\n",
    "conn_p2.commit()\n",
    "fim = time.time()\n",
    "tempo_criacao_100k = fim - inicio\n",
    "print(f\"Tempo para criar índice idx_v (100k tuplas): {tempo_criacao_100k:.6f} s\")\n",
    "\n",
    "inicio = time.time()\n",
    "cur_p2.execute(\"SELECT * FROM t WHERE v = 5;\")\n",
    "rows = cur_p2.fetchall()\n",
    "fim = time.time()\n",
    "tempo_consulta_100k = fim - inicio\n",
    "print(f\"Tempo de consulta (v = 5) com 100k tuplas: {tempo_consulta_100k:.6f} s\")\n",
    "print(\"Tuplas retornadas:\", len(rows))\n",
    "\n",
    "# Recriar tabela t com 1.000.000 de tuplas\n",
    "print(\"\\nRecriando tabela t com 1.000.000 tuplas...\")\n",
    "\n",
    "cur_p2.execute(\"DROP TABLE IF EXISTS t;\")\n",
    "cur_p2.execute(\"\"\"\n",
    "CREATE TABLE t (\n",
    "    k serial PRIMARY KEY,\n",
    "    v integer\n",
    ");\n",
    "\"\"\")\n",
    "conn_p2.commit()\n",
    "\n",
    "cur_p2.execute(\"\"\"\n",
    "INSERT INTO t(v)\n",
    "SELECT trunc(random() * 10)\n",
    "FROM generate_series(1,1000000);\n",
    "\"\"\")\n",
    "conn_p2.commit()\n",
    "print(\"Tabela t populada com 1.000.000 de tuplas.\")\n",
    "\n",
    "inicio = time.time()\n",
    "cur_p2.execute(\"CREATE INDEX idx_v ON t(v);\")\n",
    "conn_p2.commit()\n",
    "fim = time.time()\n",
    "tempo_criacao_1m = fim - inicio\n",
    "print(f\"Tempo para criar índice idx_v (1M tuplas): {tempo_criacao_1m:.6f} s\")\n",
    "\n",
    "inicio = time.time()\n",
    "cur_p2.execute(\"SELECT * FROM t WHERE v = 5;\")\n",
    "rows = cur_p2.fetchall()\n",
    "fim = time.time()\n",
    "tempo_consulta_1m = fim - inicio\n",
    "print(f\"Tempo de consulta (v = 5) com 1M tuplas: {tempo_consulta_1m:.6f} s\")\n",
    "print(\"Tuplas retornadas:\", len(rows))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9830f6",
   "metadata": {},
   "source": [
    "- O tempo para criar o índice cresce aproximadamente de forma linear com o número de tuplas.\n",
    "\n",
    "- O índice acelera consultas para v = 5, mantendo tempo < 0,1s mesmo com 1 milhão de tuplas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fc1557",
   "metadata": {},
   "source": [
    "### Tarefa 9 – Fillfactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111621ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_p2.execute(\"DROP INDEX IF EXISTS idx_v;\")\n",
    "conn_p2.commit()\n",
    "\n",
    "fillfactors = [60, 80, 90, 100]\n",
    "resultados_ff = []\n",
    "\n",
    "for ff in fillfactors:\n",
    "    idx_name = f\"idx_v_ff{ff}\"\n",
    "    cur_p2.execute(f\"DROP INDEX IF EXISTS {idx_name};\")\n",
    "    conn_p2.commit()\n",
    "\n",
    "    inicio = time.time()\n",
    "    cur_p2.execute(f\"\"\"\n",
    "        CREATE INDEX {idx_name} ON t(v)\n",
    "        WITH (fillfactor = {ff});\n",
    "    \"\"\")\n",
    "    conn_p2.commit()\n",
    "    fim = time.time()\n",
    "    tempo_criacao = fim - inicio\n",
    "\n",
    "    inicio = time.time()\n",
    "    cur_p2.execute(\"SELECT * FROM t WHERE v = 5;\")\n",
    "    cur_p2.fetchall()\n",
    "    fim = time.time()\n",
    "    tempo_consulta = fim - inicio\n",
    "\n",
    "    resultados_ff.append([ff, tempo_criacao, tempo_consulta])\n",
    "\n",
    "df_fillfactor = pd.DataFrame(resultados_ff, columns=[\"fillfactor\", \"tempo_criacao\", \"tempo_consulta\"])\n",
    "print(\"\\nResultados por fillfactor (índice ASC):\")\n",
    "print(df_fillfactor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce676bb",
   "metadata": {},
   "source": [
    "Os resultados mostram que o fillfactor tem impacto mínimo no desempenho de consultas com igualdade (v = 5) em uma tabela estática. Isso ocorre porque o fillfactor afeta principalmente operações de escrita (inserções e atualizações) e não operações de leitura. Portanto, é esperado que todos os valores testados apresentem tempos muito semelhantes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c27f45",
   "metadata": {},
   "source": [
    "### Tarefa 10 – Índices DESC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5082219d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cur_p2.execute(\"DROP INDEX IF EXISTS idx_v_desc;\")\n",
    "conn_p2.commit()\n",
    "\n",
    "inicio = time.time()\n",
    "cur_p2.execute(\"CREATE INDEX idx_v_desc ON t(v DESC NULLS FIRST);\")\n",
    "conn_p2.commit()\n",
    "fim = time.time()\n",
    "tempo_criacao_desc = fim - inicio\n",
    "print(f\"Tempo criação índice descendente idx_v_desc: {tempo_criacao_desc:.6f} s\")\n",
    "\n",
    "inicio = time.time()\n",
    "cur_p2.execute(\"SELECT * FROM t WHERE v = 5;\")\n",
    "cur_p2.fetchall()\n",
    "fim = time.time()\n",
    "tempo_consulta_desc = fim - inicio\n",
    "print(f\"Tempo consulta (v = 5) com índice descendente: {tempo_consulta_desc:.6f} s\")\n",
    "\n",
    "fillfactors = [60, 80, 90, 100]\n",
    "resultados_desc_ff = []\n",
    "\n",
    "for ff in fillfactors:\n",
    "    idx_name = f\"idx_v_desc_ff{ff}\"\n",
    "    cur_p2.execute(f\"DROP INDEX IF EXISTS {idx_name};\")\n",
    "    conn_p2.commit()\n",
    "\n",
    "    inicio = time.time()\n",
    "    cur_p2.execute(f\"\"\"\n",
    "        CREATE INDEX {idx_name} ON t(v DESC NULLS FIRST)\n",
    "        WITH (fillfactor = {ff});\n",
    "    \"\"\")\n",
    "    conn_p2.commit()\n",
    "    fim = time.time()\n",
    "    tempo_criacao = fim - inicio\n",
    "\n",
    "    inicio = time.time()\n",
    "    cur_p2.execute(\"SELECT * FROM t WHERE v = 5;\")\n",
    "    cur_p2.fetchall()\n",
    "    fim = time.time()\n",
    "    tempo_consulta = fim - inicio\n",
    "\n",
    "    resultados_desc_ff.append([ff, tempo_criacao, tempo_consulta])\n",
    "\n",
    "df_desc_fillfactor = pd.DataFrame(resultados_desc_ff, columns=[\"fillfactor\", \"tempo_criacao\", \"tempo_consulta\"])\n",
    "print(\"\\nResultados por fillfactor (índice DESC):\")\n",
    "print(df_desc_fillfactor)\n",
    "\n",
    "# Fechar conexão da Parte II\n",
    "cur_p2.close()\n",
    "conn_p2.close()\n",
    "print(\"\\nConexão da PARTE II encerrada.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e280fa28",
   "metadata": {},
   "source": [
    "- Índices descendentes apresentam desempenho muito semelhante aos índices em ordem padrão (ASC) para consultas por igualdade (v = 5).\n",
    "\n",
    "- A escolha entre ASC e DESC é mais importante quando o plano de execução precisa retornar dados ordenados por v, especialmente com ORDER BY v DESC LIMIT n.\n",
    "\n",
    "- As variações de fillfactor (60, 80, 90, 100) nos índices descendentes não alteraram de forma significativa o tempo de consulta, o que confirma que:\n",
    "\n",
    "    - fillfactor impacta principalmente operações de escrita,\n",
    "\n",
    "    - enquanto consultas de leitura simples são pouco sensíveis a essa configuração em tabelas estáticas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e591d7af",
   "metadata": {},
   "source": [
    "## Parte III"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c854b69a",
   "metadata": {},
   "source": [
    "O objetivo desta parte do trabalho é estudar o comportamento dos otimizadores de consulta dos SGBDs através do exame e análise dos planos de execução para consultas SQL sobre tabelas que serão fornecidos. Será bastante utilizado o comando EXPLAIN ANALYZE, que permite visualizar todas as etapas envolvidas no processamento de uma consulta. Usaremos para isso a tabela “movies”."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c401443",
   "metadata": {},
   "source": [
    "### Tarefa 11 – Preparaçao e Verificaçao do ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d31ff679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conectado ao banco tpch!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "DB_CONFIG = {\n",
    "    \"dbname\": \"icomp\",\n",
    "    \"user\": \"icomp\",\n",
    "    \"password\": \"icomp123\",\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": 5432\n",
    "}\n",
    "\n",
    "conn = psycopg2.connect(**DB_CONFIG)\n",
    "conn.autocommit = True\n",
    "cur = conn.cursor()\n",
    "\n",
    "print(\"Conectado ao banco tpch!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b04923fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefinedTable",
     "evalue": "table \"movie\" does not exist\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUndefinedTable\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_82454/2704594324.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msql\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"movie.sql executado com sucesso!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUndefinedTable\u001b[0m: table \"movie\" does not exist\n"
     ]
    }
   ],
   "source": [
    "caminho = '/home/icomp/Documentos/bd/Banco-de-Dados-2025-2-main/Trabalho 3/tpch4pgsql/tpch4pgsql/movie.sql'\n",
    "\n",
    "with open(caminho, \"r\", encoding=\"utf-8\") as f:\n",
    "    sql = f.read()\n",
    "\n",
    "cur.execute(sql)\n",
    "\n",
    "print(\"movie.sql executado com sucesso!\")\n",
    "\n",
    "cur.execute(\"CREATE EXTENSION IF NOT EXISTS pgstattuple;\")\n",
    "print(\"Extensão pgstattuple verificada!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16ef525d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "WITH info AS (\n",
    "    SELECT\n",
    "        ic.relname AS index_name,\n",
    "        tc.relname AS table_name,\n",
    "        pg_relation_size(ic.oid) / 8192 AS total_blocks,\n",
    "        st.n_live_tup AS num_rows,\n",
    "        i.indrelid,\n",
    "        i.indexrelid\n",
    "    FROM pg_index i\n",
    "    JOIN pg_class ic ON ic.oid = i.indexrelid\n",
    "    JOIN pg_class tc ON tc.oid = i.indrelid\n",
    "    JOIN pg_stat_all_tables st ON st.relname = tc.relname\n",
    "    WHERE tc.relname = 'movie'\n",
    ")\n",
    "SELECT\n",
    "    index_name,\n",
    "    table_name,\n",
    "    total_blocks AS blocos_totais,\n",
    "    num_rows AS num_chaves,\n",
    "    total_blocks - 1 AS blocos_folha,     -- aproximação padrão\n",
    "    (num_rows::float / (total_blocks - 1)) AS media_chaves_por_bloco\n",
    "FROM info\n",
    "ORDER BY index_name;\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "609c5cd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Índice</th>\n",
       "      <th>Tabela</th>\n",
       "      <th>Blocos totais</th>\n",
       "      <th>Nº chaves</th>\n",
       "      <th>Blocos folha</th>\n",
       "      <th>Média chaves/bloco</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Índice, Tabela, Blocos totais, Nº chaves, Blocos folha, Média chaves/bloco]\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute(query)\n",
    "dados = cur.fetchall()\n",
    "\n",
    "df_idx = pd.DataFrame(dados, columns=[\n",
    "    \"Índice\", \"Tabela\", \"Blocos totais\", \"Nº chaves\",\n",
    "    \"Blocos folha\", \"Média chaves/bloco\"\n",
    "])\n",
    "\n",
    "df_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5179aa94",
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefinedTable",
     "evalue": "relation \"movie\" does not exist\nLINE 1: SELECT COUNT(DISTINCT title) FROM movie;\n                                          ^\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUndefinedTable\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_82454/936808130.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdistinct_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdistinct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mdistinct_counts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetchone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUndefinedTable\u001b[0m: relation \"movie\" does not exist\nLINE 1: SELECT COUNT(DISTINCT title) FROM movie;\n                                          ^\n"
     ]
    }
   ],
   "source": [
    "distinct = {\n",
    "    \"movie_title\": \"SELECT COUNT(DISTINCT title) FROM movie;\",\n",
    "    \"movie_votes\": \"SELECT COUNT(DISTINCT votes) FROM movie;\"\n",
    "}\n",
    "\n",
    "distinct_counts = {}\n",
    "for idx, q in distinct.items():\n",
    "    cur.execute(q)\n",
    "    distinct_counts[idx] = cur.fetchone()[0]\n",
    "\n",
    "distinct_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1847c040",
   "metadata": {},
   "source": [
    "### Tarefa 12 – Consultas por intervalo e índices secundários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d3a66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consulta seletiva (<10 tuplas)\n",
    "cur.execute(\"\"\"\n",
    "EXPLAIN ANALYZE\n",
    "SELECT *\n",
    "FROM movie\n",
    "WHERE votes BETWEEN 53560 AND 53570;\n",
    "\"\"\")\n",
    "\n",
    "print(\"Consulta seletiva (<10 tuplas):\\n\")\n",
    "for r in cur.fetchall():\n",
    "    print(r[0])\n",
    "\n",
    "\n",
    "# Consulta ampla (>80% das tuplas)\n",
    "cur.execute(\"\"\"\n",
    "EXPLAIN ANALYZE\n",
    "SELECT *\n",
    "FROM movie\n",
    "WHERE votes > 3000;\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nConsulta ampla (>80% das tuplas):\\n\")\n",
    "for r in cur.fetchall():\n",
    "    print(r[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0071180c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d63a68a6",
   "metadata": {},
   "source": [
    "### Tarefa 13 – Comparações de operadores de agregação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebefed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPLAIN ANALYZE da consulta A (com MAX)\n",
    "cur.execute(\"\"\"\n",
    "EXPLAIN ANALYZE\n",
    "SELECT title \n",
    "FROM movie\n",
    "WHERE votes >= (SELECT MAX(votes) FROM movie);\n",
    "\"\"\")\n",
    "print(\"Consulta A — MAX():\\n\")\n",
    "for r in cur.fetchall():\n",
    "    print(r[0])\n",
    "\n",
    "\n",
    "# EXPLAIN ANALYZE da consulta B (com ALL)\n",
    "cur.execute(\"\"\"\n",
    "EXPLAIN ANALYZE\n",
    "SELECT title \n",
    "FROM movie\n",
    "WHERE votes >= ALL (SELECT votes FROM movie);\n",
    "\"\"\")\n",
    "print(\"\\nConsulta B — ALL:\\n\")\n",
    "for r in cur.fetchall():\n",
    "    print(r[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641c2067",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c380f8e1",
   "metadata": {},
   "source": [
    "### Tarefa 14 – Consultas com Junção e Seleção"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8c8b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consulta A: subconsulta\n",
    "cur.execute(\"\"\"\n",
    "EXPLAIN ANALYZE\n",
    "SELECT title \n",
    "FROM movie \n",
    "WHERE votes > (SELECT votes FROM movie WHERE title = 'Star Wars');\n",
    "\"\"\")\n",
    "\n",
    "print(\"Consulta A — Subconsulta:\\n\")\n",
    "for r in cur.fetchall():\n",
    "    print(r[0])\n",
    "\n",
    "\n",
    "# Consulta B: junção\n",
    "cur.execute(\"\"\"\n",
    "EXPLAIN ANALYZE\n",
    "SELECT m1.title\n",
    "FROM movie m1, movie m2\n",
    "WHERE m1.votes > m2.votes\n",
    "  AND m2.title = 'Star Wars';\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nConsulta B — Self Join:\\n\")\n",
    "for r in cur.fetchall():\n",
    "    print(r[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a80242",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "75835a9c",
   "metadata": {},
   "source": [
    "### Tarefa 15  – Casamento de Strings e Índices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6875628c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIKE 'I%'\n",
    "cur.execute(\"\"\"\n",
    "EXPLAIN\n",
    "SELECT title \n",
    "FROM movie \n",
    "WHERE title LIKE 'I%';\n",
    "\"\"\")\n",
    "print(\"Consulta 1 — LIKE 'I%':\\n\")\n",
    "for r in cur.fetchall():\n",
    "    print(r[0])\n",
    "\n",
    "\n",
    "# SUBSTR(title,1,1) = 'I'\n",
    "cur.execute(\"\"\"\n",
    "EXPLAIN\n",
    "SELECT title\n",
    "FROM movie\n",
    "WHERE substr(title, 1, 1) = 'I';\n",
    "\"\"\")\n",
    "print(\"\\nConsulta 2 — SUBSTR(title,1,1) = 'I':\\n\")\n",
    "for r in cur.fetchall():\n",
    "    print(r[0])\n",
    "\n",
    "\n",
    "# LIKE '%A'\n",
    "cur.execute(\"\"\"\n",
    "EXPLAIN\n",
    "SELECT title \n",
    "FROM movie \n",
    "WHERE title LIKE '%A';\n",
    "\"\"\")\n",
    "print(\"\\nConsulta 3 — LIKE '%A':\\n\")\n",
    "for r in cur.fetchall():\n",
    "    print(r[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ff33e7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f854d11e",
   "metadata": {},
   "source": [
    "### Tarefa 16 – Verificação da hipótese de distribuição uniforme na estimativa de seletividade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a499a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consulta 1 — votes < 1000\n",
    "cur.execute(\"\"\"\n",
    "EXPLAIN\n",
    "SELECT title\n",
    "FROM movie\n",
    "WHERE votes < 1000;\n",
    "\"\"\")\n",
    "print(\"Consulta 1 — votes < 1000:\\n\")\n",
    "for r in cur.fetchall():\n",
    "    print(r[0])\n",
    "\n",
    "\n",
    "# Consulta 2 — votes > 40000\n",
    "cur.execute(\"\"\"\n",
    "EXPLAIN\n",
    "SELECT title\n",
    "FROM movie\n",
    "WHERE votes > 40000;\n",
    "\"\"\")\n",
    "print(\"\\nConsulta 2 — votes > 40000:\\n\")\n",
    "for r in cur.fetchall():\n",
    "    print(r[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03122ab",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09c6df6d",
   "metadata": {},
   "source": [
    "## Parte IV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a530dde",
   "metadata": {},
   "source": [
    "O objetivo desta parte do trabalho é experimentar estratégias para utilização de transações e níveis de isolamento em SGBDs relacionais. As tarefas envolvem uma simulação de um sistema de reservas de passagem áreas. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b1f50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_CONFIG = {\n",
    "    \"dbname\": \"tpch\",\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"test123\",\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": 5432\n",
    "}\n",
    "\n",
    "def reset_db():\n",
    "    conn = psycopg2.connect(**DB_CONFIG)\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    cur.execute(\"DROP TABLE IF EXISTS assentos;\")\n",
    "    cur.execute(\"\"\"\n",
    "        CREATE TABLE assentos(\n",
    "            num_voo INT PRIMARY KEY,\n",
    "            disp BOOLEAN\n",
    "        );\n",
    "    \"\"\")\n",
    "\n",
    "    # 200 assentos inicialmente livres\n",
    "    cur.executemany(\"INSERT INTO assentos VALUES (%s, true);\", [(i,) for i in range(1, 201)])\n",
    "\n",
    "    conn.commit()\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "\n",
    "reset_db()\n",
    "print(\"Tabela assentos pronta.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1252fc44",
   "metadata": {},
   "source": [
    "### Tarefa 17 – Código das Versões A e B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bf2782",
   "metadata": {},
   "source": [
    "Versão A - Uma única transação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3f314f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reserva_versaoA(isolation_level):\n",
    "\n",
    "    conn = psycopg2.connect(**DB_CONFIG)\n",
    "    conn.set_session(isolation_level=isolation_level)\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    tentativas = 0\n",
    "\n",
    "    while True:\n",
    "        tentativas += 1\n",
    "        try:\n",
    "            # Passo 1 — escolher 1 assento livre e BLOQUEAR apenas ele\n",
    "            cur.execute(\"\"\"\n",
    "                SELECT num_voo \n",
    "                FROM assentos \n",
    "                WHERE disp = true \n",
    "                ORDER BY random()\n",
    "                LIMIT 1\n",
    "                FOR UPDATE;\n",
    "            \"\"\")\n",
    "            row = cur.fetchone()\n",
    "\n",
    "            # Nenhum assento livre → fim\n",
    "            if not row:\n",
    "                conn.rollback()\n",
    "                break\n",
    "\n",
    "            escolhido = row[0]\n",
    "\n",
    "            # Passo 2 — espera de 1s (cliente escolhendo)\n",
    "            time.sleep(1)\n",
    "\n",
    "            # Passo 3 — marcar como ocupado\n",
    "            cur.execute(\"\"\"\n",
    "                UPDATE assentos \n",
    "                SET disp = false \n",
    "                WHERE num_voo = %s;\n",
    "            \"\"\", (escolhido,))\n",
    "\n",
    "            conn.commit()\n",
    "            break  # reserva feita com sucesso\n",
    "\n",
    "        except psycopg2.errors.SerializationFailure:\n",
    "            # conflitos serializáveis → tentar de novo\n",
    "            conn.rollback()\n",
    "            continue\n",
    "\n",
    "        except psycopg2.Error as e:\n",
    "            # erros inesperados devem ser reportados\n",
    "            conn.rollback()\n",
    "            print(\"Erro inesperado na versão A:\", e)\n",
    "            break\n",
    "\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    return tentativas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48836f96",
   "metadata": {},
   "source": [
    "Versão b - Duas transações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "05728698",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reserva_versaoB(isolation_level):\n",
    "\n",
    "    tentativas = 0\n",
    "\n",
    "    while True:\n",
    "        tentativas += 1\n",
    "\n",
    "        try:\n",
    "            # ================================\n",
    "            # TRANSAÇÃO 1: obter 1 assento livre\n",
    "            # ================================\n",
    "            conn1 = psycopg2.connect(**DB_CONFIG)\n",
    "            conn1.set_session(isolation_level=isolation_level)\n",
    "            cur1 = conn1.cursor()\n",
    "\n",
    "            cur1.execute(\"\"\"\n",
    "                SELECT num_voo \n",
    "                FROM assentos \n",
    "                WHERE disp = true \n",
    "                ORDER BY random()\n",
    "                LIMIT 1;\n",
    "            \"\"\")\n",
    "\n",
    "            row = cur1.fetchone()\n",
    "\n",
    "            if not row:\n",
    "                conn1.commit()\n",
    "                conn1.close()\n",
    "                break  # nenhum assento disponível\n",
    "\n",
    "            escolhido = row[0]\n",
    "\n",
    "            conn1.commit()\n",
    "            conn1.close()\n",
    "\n",
    "            # ================================\n",
    "            # PASSO 2 — escolha do cliente\n",
    "            # ================================\n",
    "            time.sleep(1)\n",
    "\n",
    "            # ================================\n",
    "            # TRANSAÇÃO 2: tentar reservar\n",
    "            # ================================\n",
    "            conn2 = psycopg2.connect(**DB_CONFIG)\n",
    "            conn2.set_session(isolation_level=isolation_level)\n",
    "            cur2 = conn2.cursor()\n",
    "\n",
    "            cur2.execute(\"\"\"\n",
    "                UPDATE assentos\n",
    "                SET disp = false\n",
    "                WHERE num_voo = %s AND disp = true;\n",
    "            \"\"\", (escolhido,))\n",
    "\n",
    "            if cur2.rowcount == 1:\n",
    "                conn2.commit()\n",
    "                conn2.close()\n",
    "                break  # reserva concluída\n",
    "            else:\n",
    "                conn2.rollback()\n",
    "                conn2.close()\n",
    "                continue  # alguém já pegou → tentar novamente\n",
    "\n",
    "        except psycopg2.errors.SerializationFailure:\n",
    "            # conflito serializável → repetir tentativa\n",
    "            continue\n",
    "\n",
    "        except Exception as e:\n",
    "            # erro inesperado → reportar e quebrar\n",
    "            print(\"Erro inesperado na versão B:\", e)\n",
    "            break\n",
    "\n",
    "    return tentativas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd4b561",
   "metadata": {},
   "source": [
    "### Tarefa 18 – Executar experimentos e gerar gráficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac39de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import threading\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# k usados no experimento\n",
    "k_values = [1, 2, 4, 6, 8, 10]\n",
    "\n",
    "# estrutura para armazenar os tempos de cada experimento\n",
    "resultados = {\n",
    "    \"A_READ_COMMITTED\": [],\n",
    "    \"A_SERIALIZABLE\": [],\n",
    "    \"B_READ_COMMITTED\": [],\n",
    "    \"B_SERIALIZABLE\": []\n",
    "}\n",
    "\n",
    "estatisticas_tentativas = []\n",
    "\n",
    "def executar_experimento(k, versao_func, isolation_level, num_clientes=200):\n",
    "    \"\"\"\n",
    "    Executa um experimento com:\n",
    "    - k threads (agentes de viagem)\n",
    "    - num_clientes clientes (default = 200)\n",
    "    - versao_func: reserva_versaoA ou reserva_versaoB\n",
    "    - isolation_level: 'READ COMMITTED' ou 'SERIALIZABLE'\n",
    "\n",
    "    Retorna:\n",
    "        tempo_total (float),\n",
    "        tentativas_total (lista de tentativas por cliente),\n",
    "        estatisticas (dict com Min, Max, Média)\n",
    "    \"\"\"\n",
    "\n",
    "    # Começa sempre com a tabela de 200 assentos livres\n",
    "    reset_db()\n",
    "\n",
    "    inicio = time.time()\n",
    "    tentativas_total = []\n",
    "\n",
    "    contador = {\"cliente\": 0}\n",
    "    lock = threading.Lock()\n",
    "\n",
    "    def worker():\n",
    "        while True:\n",
    "            # pegar \"um cliente\" para esta thread\n",
    "            with lock:\n",
    "                if contador[\"cliente\"] >= num_clientes:\n",
    "                    return\n",
    "                contador[\"cliente\"] += 1\n",
    "\n",
    "            # atende um cliente (uma reserva completa)\n",
    "            tentativas = versao_func(isolation_level)\n",
    "            tentativas_total.append(tentativas)\n",
    "\n",
    "    # cria k threads/agentes\n",
    "    threads = [threading.Thread(target=worker) for _ in range(k)]\n",
    "\n",
    "    # inicia e aguarda todas\n",
    "    for t in threads:\n",
    "        t.start()\n",
    "    for t in threads:\n",
    "        t.join()\n",
    "\n",
    "    tempo_total = time.time() - inicio\n",
    "\n",
    "    # ---- estatísticas das tentativas ----\n",
    "    arr = np.array(tentativas_total)\n",
    "    estatisticas = {\n",
    "        \"Min\": arr.min(),\n",
    "        \"Max\": arr.max(),\n",
    "        \"Média\": arr.mean()\n",
    "    }\n",
    "\n",
    "    return tempo_total, tentativas_total, estatisticas\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffa8045",
   "metadata": {},
   "source": [
    "Executar Experimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab3752a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in k_values:\n",
    "    # Versão A - Read Committed\n",
    "    t, tent, stats = executar_experimento(k, reserva_versaoA, \"READ COMMITTED\")\n",
    "    resultados[\"A_READ_COMMITTED\"].append(t)\n",
    "\n",
    "    estatisticas_tentativas.append({\n",
    "        \"k\": k,\n",
    "        \"Versão\": \"A\",\n",
    "        \"Isolamento\": \"READ COMMITTED\",\n",
    "        \"Min\": stats[\"Min\"],\n",
    "        \"Max\": stats[\"Max\"],\n",
    "        \"Média\": stats[\"Média\"]\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cc17b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in k_values:\n",
    "    # Versão A - Serializable\n",
    "    t, tent, stats = executar_experimento(k, reserva_versaoA, \"SERIALIZABLE\")\n",
    "    resultados[\"A_SERIALIZABLE\"].append(t)\n",
    "\n",
    "    estatisticas_tentativas.append({\n",
    "        \"k\": k,\n",
    "        \"Versão\": \"A\",\n",
    "        \"Isolamento\": \"SERIALIZABLE\",\n",
    "        \"Min\": stats[\"Min\"],\n",
    "        \"Max\": stats[\"Max\"],\n",
    "        \"Média\": stats[\"Média\"]\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d91c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in k_values:\n",
    "    # Versão B - Read Committed\n",
    "    t, tent, stats = executar_experimento(k, reserva_versaoB, \"READ COMMITTED\")\n",
    "    resultados[\"B_READ_COMMITTED\"].append(t)\n",
    "\n",
    "    estatisticas_tentativas.append({\n",
    "        \"k\": k,\n",
    "        \"Versão\": \"B\",\n",
    "        \"Isolamento\": \"READ COMMITTED\",\n",
    "        \"Min\": stats[\"Min\"],\n",
    "        \"Max\": stats[\"Max\"],\n",
    "        \"Média\": stats[\"Média\"]\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5944f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in k_values:\n",
    "    # Versão B - Serializable\n",
    "    t, tent, stats = executar_experimento(k, reserva_versaoB, \"SERIALIZABLE\")\n",
    "    resultados[\"B_SERIALIZABLE\"].append(t)\n",
    "\n",
    "    estatisticas_tentativas.append({\n",
    "        \"k\": k,\n",
    "        \"Versão\": \"B\",\n",
    "        \"Isolamento\": \"SERIALIZABLE\",\n",
    "        \"Min\": stats[\"Min\"],\n",
    "        \"Max\": stats[\"Max\"],\n",
    "        \"Média\": stats[\"Média\"]\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947726c0",
   "metadata": {},
   "source": [
    "Gerar Gráficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835209e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerar_grafico(nome, valores, titulo):\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.plot(k_values, valores, marker='o')\n",
    "    plt.xlabel(\"Número de agentes (k)\")\n",
    "    plt.ylabel(\"Tempo total (s)\")\n",
    "    plt.title(titulo)\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Range fixo para facilitar comparação entre gráficos \n",
    "    plt.ylim(0, 300)  \n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "gerar_grafico(\n",
    "    \"A_READ_COMMITTED\",\n",
    "    resultados[\"A_READ_COMMITTED\"],\n",
    "    \"Versão A – Read Committed\"\n",
    ")\n",
    "\n",
    "gerar_grafico(\n",
    "    \"A_SERIALIZABLE\",\n",
    "    resultados[\"A_SERIALIZABLE\"],\n",
    "    \"Versão A – Serializable\"\n",
    ")\n",
    "\n",
    "gerar_grafico(\n",
    "    \"B_READ_COMMITTED\",\n",
    "    resultados[\"B_READ_COMMITTED\"],\n",
    "    \"Versão B – Read Committed\"\n",
    ")\n",
    "\n",
    "gerar_grafico(\n",
    "    \"B_SERIALIZABLE\",\n",
    "    resultados[\"B_SERIALIZABLE\"],\n",
    "    \"Versão B – Serializable\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ea69ca",
   "metadata": {},
   "source": [
    "### Tarefa 19 — Tabela de tentativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549d1016",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Criar DataFrame final\n",
    "df_tentativas = pd.DataFrame(estatisticas_tentativas)\n",
    "\n",
    "# Ordenar \n",
    "df_tentativas = df_tentativas.sort_values(by=[\"Versão\", \"Isolamento\", \"k\"])\n",
    "\n",
    "df_tentativas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f3efc7",
   "metadata": {},
   "source": [
    "### Tarefa 20 - Análise dos Resultados\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabed156",
   "metadata": {},
   "source": [
    "1. Versão A — Read Committed\n",
    "\n",
    "Na versão A com Read Committed, todos os clientes concluíram a reserva sempre na primeira tentativa.\n",
    "\n",
    "(Min = Max = Média = 1)\n",
    "\n",
    "Isso ocorre porque:\n",
    "\n",
    "- A leitura, a espera de 1 segundo e a escrita são executadas dentro de uma única transação.\n",
    "\n",
    "- No nível Read Committed, a leitura não é bloqueada e o SGBD não precisa garantir serialização global.\n",
    "\n",
    "- Conflitos reais só acontecem na escrita, e a chance de dois agentes reservarem o mesmo assento simultaneamente é baixa.\n",
    "\n",
    "*Conclusão*: desempenho estável, sem retrabalho e tempos compatíveis com o aumento de k.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36605ec",
   "metadata": {},
   "source": [
    "2. Versão A — Serializable\n",
    "\n",
    "Este foi o cenário mais custoso da simulação. O número de tentativas aumentou significativamente conforme k cresceu, chegando a até 8 retries.\n",
    "\n",
    "Motivos:\n",
    "\n",
    "- O nível Serializable exige que a transação inteira seja equivalente a uma execução isolada.\n",
    "\n",
    "- A versão A mantém a transação aberta durante o tempo de espera de 1 segundo, aumentando a janela crítica.\n",
    "\n",
    "- Vários agentes leem o mesmo estado dos assentos e tentam reservar posições semelhantes.\n",
    "\n",
    "- O PostgreSQL detecta conflitos de serialização (como phantom reads e write-write conflicts) e aborta transações, obrigando novas tentativas.\n",
    "\n",
    "*Conclusão:* alta contenção, muitos abortos de transação e pior desempenho entre todas as combinações."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ced971",
   "metadata": {},
   "source": [
    "3. Versão B — Read Committed\n",
    "\n",
    "A versão B apresentou apenas uma tentativa por cliente em todos os valores de k.\n",
    "\n",
    "Isso acontece porque:\n",
    "\n",
    "- A leitura e a escrita acontecem em transações separadas, ambas muito curtas.\n",
    "\n",
    "- O tempo de espera de 1 segundo ocorre fora de qualquer transação, reduzindo drasticamente a chance de conflito.\n",
    "\n",
    "- A escrita é rápida o suficiente para não gerar bloqueios significativos.\n",
    "\n",
    "*Conclusão:* excelente desempenho e nenhuma tentativa extra, mesmo com alta concorrência."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7981f0fa",
   "metadata": {},
   "source": [
    "4. Versão B — Serializable\n",
    "\n",
    "Mesmo sob Serializable, a versão B manteve Min = Max = Média = 1.\n",
    "Ou seja, a serialização não gerou overhead significativo.\n",
    "\n",
    "Razões:\n",
    "\n",
    "- Como a transação de escrita é extremamente curta, as chances de conflito são mínimas.\n",
    "\n",
    "- A separação entre leitura e escrita impede phantoms e reduz o risco de abortos.\n",
    "\n",
    "*Conclusão:* comportamento extremamente eficiente, mostrando que a versão B é robusta mesmo no nível de isolamento mais forte."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
