{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0cc7dd7",
   "metadata": {},
   "source": [
    "# Introdução à Banco de Dados | Trabalho Prático III\n",
    "Abel Severo Rocha, Ana Carla Fernandes, Natasha Caxias\n",
    "\n",
    "Prof. Dr. Altigran Soares da Silva"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61a0749",
   "metadata": {},
   "source": [
    "## Parte I\n",
    "Verificação dos parâmetros do hardware e do software utilizado e familiarização com o ambiente do PostgreSQL."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78568dea",
   "metadata": {},
   "source": [
    "### Tarefa 1 - Identificação do Sistema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26ea43b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: psycopg2-binary in /home/desktoop2/.local/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (2.9.11)\n",
      "Requirement already satisfied: pandas in /home/desktoop2/.local/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (2.3.3)\n",
      "Requirement already satisfied: tabulate in /home/desktoop2/.local/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (0.9.0)\n",
      "Requirement already satisfied: mock in /home/desktoop2/.local/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (5.2.0)\n",
      "Requirement already satisfied: numpy in /home/desktoop2/.local/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (1.26.4)\n",
      "Requirement already satisfied: matplotlib in /home/desktoop2/.local/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (3.8.4)\n",
      "Requirement already satisfied: matplotlib-inline in /home/desktoop2/.local/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (0.1.6)\n",
      "Requirement already satisfied: jupyter in /home/desktoop2/.local/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (1.1.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/desktoop2/.local/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 2)) (2025.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/desktoop2/.local/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 2)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas->-r requirements.txt (line 2)) (2022.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib->-r requirements.txt (line 6)) (2.4.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/desktoop2/.local/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 6)) (1.3.2)\n",
      "Requirement already satisfied: pillow>=8 in /usr/lib/python3/dist-packages (from matplotlib->-r requirements.txt (line 6)) (9.0.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/lib/python3/dist-packages (from matplotlib->-r requirements.txt (line 6)) (4.29.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/lib/python3/dist-packages (from matplotlib->-r requirements.txt (line 6)) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/desktoop2/.local/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 6)) (25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/lib/python3/dist-packages (from matplotlib->-r requirements.txt (line 6)) (1.3.2)\n",
      "Requirement already satisfied: traitlets in /home/desktoop2/.local/lib/python3.10/site-packages (from matplotlib-inline->-r requirements.txt (line 7)) (5.14.3)\n",
      "Requirement already satisfied: ipykernel in /home/desktoop2/.local/lib/python3.10/site-packages (from jupyter->-r requirements.txt (line 8)) (7.1.0)\n",
      "Requirement already satisfied: jupyter-console in /home/desktoop2/.local/lib/python3.10/site-packages (from jupyter->-r requirements.txt (line 8)) (6.6.3)\n",
      "Requirement already satisfied: ipywidgets in /home/desktoop2/.local/lib/python3.10/site-packages (from jupyter->-r requirements.txt (line 8)) (8.1.8)\n",
      "Requirement already satisfied: nbconvert in /home/desktoop2/.local/lib/python3.10/site-packages (from jupyter->-r requirements.txt (line 8)) (7.16.6)\n",
      "Requirement already satisfied: notebook in /home/desktoop2/.local/lib/python3.10/site-packages (from jupyter->-r requirements.txt (line 8)) (7.5.0)\n",
      "Requirement already satisfied: jupyterlab in /home/desktoop2/.local/lib/python3.10/site-packages (from jupyter->-r requirements.txt (line 8)) (4.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 2)) (1.16.0)\n",
      "Requirement already satisfied: pyzmq>=25 in /home/desktoop2/.local/lib/python3.10/site-packages (from ipykernel->jupyter->-r requirements.txt (line 8)) (27.1.0)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /home/desktoop2/.local/lib/python3.10/site-packages (from ipykernel->jupyter->-r requirements.txt (line 8)) (1.8.17)\n",
      "Requirement already satisfied: tornado>=6.2 in /home/desktoop2/.local/lib/python3.10/site-packages (from ipykernel->jupyter->-r requirements.txt (line 8)) (6.5.2)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /home/desktoop2/.local/lib/python3.10/site-packages (from ipykernel->jupyter->-r requirements.txt (line 8)) (8.37.0)\n",
      "Requirement already satisfied: psutil>=5.7 in /usr/lib/python3/dist-packages (from ipykernel->jupyter->-r requirements.txt (line 8)) (5.9.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /home/desktoop2/.local/lib/python3.10/site-packages (from ipykernel->jupyter->-r requirements.txt (line 8)) (5.9.1)\n",
      "Requirement already satisfied: nest-asyncio>=1.4 in /home/desktoop2/.local/lib/python3.10/site-packages (from ipykernel->jupyter->-r requirements.txt (line 8)) (1.6.0)\n",
      "Requirement already satisfied: comm>=0.1.1 in /home/desktoop2/.local/lib/python3.10/site-packages (from ipykernel->jupyter->-r requirements.txt (line 8)) (0.2.3)\n",
      "Requirement already satisfied: jupyter-client>=8.0.0 in /home/desktoop2/.local/lib/python3.10/site-packages (from ipykernel->jupyter->-r requirements.txt (line 8)) (8.6.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in /home/desktoop2/.local/lib/python3.10/site-packages (from ipywidgets->jupyter->-r requirements.txt (line 8)) (4.0.15)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /home/desktoop2/.local/lib/python3.10/site-packages (from ipywidgets->jupyter->-r requirements.txt (line 8)) (3.0.16)\n",
      "Requirement already satisfied: pygments in /usr/lib/python3/dist-packages (from jupyter-console->jupyter->-r requirements.txt (line 8)) (2.11.2)\n",
      "Requirement already satisfied: prompt-toolkit>=3.0.30 in /home/desktoop2/.local/lib/python3.10/site-packages (from jupyter-console->jupyter->-r requirements.txt (line 8)) (3.0.52)\n",
      "Requirement already satisfied: httpx<1,>=0.25.0 in /home/desktoop2/.local/lib/python3.10/site-packages (from jupyterlab->jupyter->-r requirements.txt (line 8)) (0.28.1)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in /home/desktoop2/.local/lib/python3.10/site-packages (from jupyterlab->jupyter->-r requirements.txt (line 8)) (2.0.5)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in /home/desktoop2/.local/lib/python3.10/site-packages (from jupyterlab->jupyter->-r requirements.txt (line 8)) (2.3.0)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.28.0 in /home/desktoop2/.local/lib/python3.10/site-packages (from jupyterlab->jupyter->-r requirements.txt (line 8)) (2.28.0)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in /home/desktoop2/.local/lib/python3.10/site-packages (from jupyterlab->jupyter->-r requirements.txt (line 8)) (3.1.6)\n",
      "Requirement already satisfied: tomli>=1.2.2 in /home/desktoop2/.local/lib/python3.10/site-packages (from jupyterlab->jupyter->-r requirements.txt (line 8)) (2.3.0)\n",
      "Requirement already satisfied: setuptools>=41.1.0 in /usr/lib/python3/dist-packages (from jupyterlab->jupyter->-r requirements.txt (line 8)) (59.6.0)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /home/desktoop2/.local/lib/python3.10/site-packages (from jupyterlab->jupyter->-r requirements.txt (line 8)) (2.17.0)\n",
      "Requirement already satisfied: notebook-shim>=0.2 in /home/desktoop2/.local/lib/python3.10/site-packages (from jupyterlab->jupyter->-r requirements.txt (line 8)) (0.2.4)\n",
      "Requirement already satisfied: bleach[css]!=5.0.0 in /home/desktoop2/.local/lib/python3.10/site-packages (from nbconvert->jupyter->-r requirements.txt (line 8)) (6.3.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/lib/python3/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 8)) (4.10.0)\n",
      "Requirement already satisfied: defusedxml in /home/desktoop2/.local/lib/python3.10/site-packages (from nbconvert->jupyter->-r requirements.txt (line 8)) (0.7.1)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /home/desktoop2/.local/lib/python3.10/site-packages (from nbconvert->jupyter->-r requirements.txt (line 8)) (3.1.4)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /home/desktoop2/.local/lib/python3.10/site-packages (from nbconvert->jupyter->-r requirements.txt (line 8)) (1.5.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /home/desktoop2/.local/lib/python3.10/site-packages (from nbconvert->jupyter->-r requirements.txt (line 8)) (0.3.0)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /home/desktoop2/.local/lib/python3.10/site-packages (from nbconvert->jupyter->-r requirements.txt (line 8)) (0.10.2)\n",
      "Requirement already satisfied: markupsafe>=2.0 in /usr/lib/python3/dist-packages (from nbconvert->jupyter->-r requirements.txt (line 8)) (2.0.1)\n",
      "Requirement already satisfied: nbformat>=5.7 in /home/desktoop2/.local/lib/python3.10/site-packages (from nbconvert->jupyter->-r requirements.txt (line 8)) (5.10.4)\n",
      "Requirement already satisfied: typing_extensions>=4.0.0 in /home/desktoop2/.local/lib/python3.10/site-packages (from async-lru>=1.0.0->jupyterlab->jupyter->-r requirements.txt (line 8)) (4.15.0)\n",
      "Requirement already satisfied: webencodings in /usr/lib/python3/dist-packages (from bleach[css]!=5.0.0->nbconvert->jupyter->-r requirements.txt (line 8)) (0.5.1)\n",
      "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /home/desktoop2/.local/lib/python3.10/site-packages (from bleach[css]!=5.0.0->nbconvert->jupyter->-r requirements.txt (line 8)) (1.4.0)\n",
      "Requirement already satisfied: httpcore==1.* in /home/desktoop2/.local/lib/python3.10/site-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter->-r requirements.txt (line 8)) (1.0.9)\n",
      "Requirement already satisfied: anyio in /home/desktoop2/.local/lib/python3.10/site-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter->-r requirements.txt (line 8)) (4.11.0)\n",
      "Requirement already satisfied: idna in /usr/lib/python3/dist-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter->-r requirements.txt (line 8)) (3.3)\n",
      "Requirement already satisfied: certifi in /usr/lib/python3/dist-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter->-r requirements.txt (line 8)) (2020.6.20)\n",
      "Requirement already satisfied: h11>=0.16 in /home/desktoop2/.local/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.25.0->jupyterlab->jupyter->-r requirements.txt (line 8)) (0.16.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/desktoop2/.local/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 8)) (0.19.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/lib/python3/dist-packages (from ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 8)) (4.8.0)\n",
      "Requirement already satisfied: decorator in /usr/lib/python3/dist-packages (from ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 8)) (4.4.2)\n",
      "Requirement already satisfied: exceptiongroup in /home/desktoop2/.local/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 8)) (1.3.1)\n",
      "Requirement already satisfied: stack_data in /home/desktoop2/.local/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 8)) (0.6.3)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /home/desktoop2/.local/lib/python3.10/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter->-r requirements.txt (line 8)) (4.5.0)\n",
      "Requirement already satisfied: websocket-client>=1.7 in /home/desktoop2/.local/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 8)) (1.9.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /home/desktoop2/.local/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 8)) (0.18.1)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in /home/desktoop2/.local/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 8)) (0.23.1)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in /home/desktoop2/.local/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 8)) (25.1.0)\n",
      "Requirement already satisfied: overrides>=5.0 in /home/desktoop2/.local/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 8)) (7.7.0)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in /home/desktoop2/.local/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 8)) (1.8.3)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /home/desktoop2/.local/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 8)) (0.5.3)\n",
      "Requirement already satisfied: jupyter-events>=0.11.0 in /home/desktoop2/.local/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 8)) (0.12.0)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in /home/desktoop2/.local/lib/python3.10/site-packages (from jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter->-r requirements.txt (line 8)) (4.25.1)\n",
      "Requirement already satisfied: json5>=0.9.0 in /home/desktoop2/.local/lib/python3.10/site-packages (from jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter->-r requirements.txt (line 8)) (0.12.1)\n",
      "Requirement already satisfied: requests>=2.31 in /home/desktoop2/.local/lib/python3.10/site-packages (from jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter->-r requirements.txt (line 8)) (2.32.5)\n",
      "Requirement already satisfied: babel>=2.10 in /home/desktoop2/.local/lib/python3.10/site-packages (from jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter->-r requirements.txt (line 8)) (2.17.0)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in /home/desktoop2/.local/lib/python3.10/site-packages (from nbformat>=5.7->nbconvert->jupyter->-r requirements.txt (line 8)) (2.21.2)\n",
      "Requirement already satisfied: wcwidth in /home/desktoop2/.local/lib/python3.10/site-packages (from prompt-toolkit>=3.0.30->jupyter-console->jupyter->-r requirements.txt (line 8)) (0.2.14)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/desktoop2/.local/lib/python3.10/site-packages (from anyio->httpx<1,>=0.25.0->jupyterlab->jupyter->-r requirements.txt (line 8)) (1.3.1)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /home/desktoop2/.local/lib/python3.10/site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 8)) (25.1.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /home/desktoop2/.local/lib/python3.10/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 8)) (0.8.5)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/desktoop2/.local/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter->-r requirements.txt (line 8)) (0.29.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/desktoop2/.local/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter->-r requirements.txt (line 8)) (25.4.0)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/desktoop2/.local/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter->-r requirements.txt (line 8)) (0.37.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/desktoop2/.local/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter->-r requirements.txt (line 8)) (2025.9.1)\n",
      "Requirement already satisfied: rfc3339-validator in /home/desktoop2/.local/lib/python3.10/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 8)) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in /home/desktoop2/.local/lib/python3.10/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 8)) (0.1.1)\n",
      "Requirement already satisfied: pyyaml>=5.3 in /usr/lib/python3/dist-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 8)) (5.4.1)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /home/desktoop2/.local/lib/python3.10/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 8)) (4.0.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests>=2.31->jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter->-r requirements.txt (line 8)) (1.26.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/desktoop2/.local/lib/python3.10/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter->-r requirements.txt (line 8)) (3.4.4)\n",
      "Requirement already satisfied: ptyprocess in /usr/lib/python3/dist-packages (from terminado>=0.8.3->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 8)) (0.7.0)\n",
      "Requirement already satisfied: pure-eval in /home/desktoop2/.local/lib/python3.10/site-packages (from stack_data->ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 8)) (0.2.3)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/desktoop2/.local/lib/python3.10/site-packages (from stack_data->ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 8)) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/desktoop2/.local/lib/python3.10/site-packages (from stack_data->ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 8)) (3.0.1)\n",
      "Requirement already satisfied: uri-template in /home/desktoop2/.local/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter->-r requirements.txt (line 8)) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in /home/desktoop2/.local/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter->-r requirements.txt (line 8)) (25.10.0)\n",
      "Requirement already satisfied: fqdn in /home/desktoop2/.local/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter->-r requirements.txt (line 8)) (1.5.1)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /home/desktoop2/.local/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter->-r requirements.txt (line 8)) (3.0.0)\n",
      "Requirement already satisfied: isoduration in /home/desktoop2/.local/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter->-r requirements.txt (line 8)) (20.11.0)\n",
      "Requirement already satisfied: rfc3987-syntax>=1.1.0 in /home/desktoop2/.local/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter->-r requirements.txt (line 8)) (1.1.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /home/desktoop2/.local/lib/python3.10/site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 8)) (2.0.0)\n",
      "Requirement already satisfied: pycparser in /home/desktoop2/.local/lib/python3.10/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 8)) (2.23)\n",
      "Requirement already satisfied: lark>=1.2.2 in /home/desktoop2/.local/lib/python3.10/site-packages (from rfc3987-syntax>=1.1.0->jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter->-r requirements.txt (line 8)) (1.3.1)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /home/desktoop2/.local/lib/python3.10/site-packages (from isoduration->jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter->-r requirements.txt (line 8)) (1.4.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca6601b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "import datetime\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "from psycopg2.extras import RealDictCursor\n",
    "from tpch_pgsql import main as tpch_pgsql\n",
    "from tpch4pgsql import postgresqldb as pgdb, result as r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0d100a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostrarSoInfo():\n",
    "    \n",
    "    soInfo = platform.freedesktop_os_release()\n",
    "    print(\"\\n--------- Sistema Operacional (SO) ---------\\n\")\n",
    "    print(\"Sistema Operacional \", platform.system())\n",
    "    print(\"Versão              \", soInfo[\"VERSION\"])\n",
    "    print(\"Release (kernel)    \", platform.release())\n",
    "    print(\"Arquitetura         \", platform.machine())\n",
    "    print(\"Distribuição        \", soInfo[\"NAME\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fffed5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostrarHardwareInfo():\n",
    "\n",
    "    cpuInfo = {}\n",
    "    with open(\"/proc/cpuinfo\") as f:\n",
    "        for line in f:\n",
    "            if \":\" in line:\n",
    "                k, v = line.split(\":\", 1)\n",
    "                cpuInfo[k.strip()] = v.strip()\n",
    "    \n",
    "    ramInfo = {}\n",
    "    with open(\"/proc/meminfo\") as f:\n",
    "        for line in f:\n",
    "            k, v = line.split(\":\", 1)\n",
    "            ramInfo[k] = v.strip()\n",
    "\n",
    "    print(\"\\n------------- Sobre o Hardware -------------\\n\")\n",
    "    print(\"Processador:\")\n",
    "    print(\"  • Modelo          \", cpuInfo[\"model name\"])\n",
    "    print(\"  • CPUs lógicas    \", os.cpu_count())\n",
    "    print(\"  • Clock base      \", cpuInfo[\"cpu MHz\"], \"MHz\")\n",
    "\n",
    "    print(\"\\nCache:\")\n",
    "    with open(\"/sys/devices/system/cpu/cpu0/cache/index0/size\") as f:\n",
    "        print(\"  • L1d             \", f.read().strip()[:-1]+\" kB\")\n",
    "    with open(\"/sys/devices/system/cpu/cpu0/cache/index1/size\") as f:\n",
    "        print(\"  • L1i             \", f.read().strip()[:-1]+\" kB\")\n",
    "    with open(\"/sys/devices/system/cpu/cpu0/cache/index2/size\") as f:\n",
    "        print(\"  • L2              \", f.read().strip()[:-1]+\" kB\")\n",
    "    with open(\"/sys/devices/system/cpu/cpu0/cache/index3/size\") as f:\n",
    "        print(\"  • L3              \", f.read().strip()[:-1]+\" kB\")\n",
    "\n",
    "    print(\"\\nMemória RAM:\")\n",
    "    print(\"  • Total           \", ramInfo[\"MemTotal\"])\n",
    "    print(\"  • Livre           \", ramInfo[\"MemFree\"])\n",
    "    print(\"  • Disponível      \", ramInfo[\"MemAvailable\"])\n",
    "\n",
    "    total, usado, livre = shutil.disk_usage(\"/\")\n",
    "    print(\"\\nDisco:\")\n",
    "    print(f\"  • Total            {total/1024**3:.2f} GB\")\n",
    "    print(f\"  • Usado            {usado/1024**3:.2f} GB\")\n",
    "    print(f\"  • Livre            {livre/1024**3:.2f} GB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97fa38fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------- Sistema Operacional (SO) ---------\n",
      "\n",
      "Sistema Operacional  Linux\n",
      "Versão               22.04.5 LTS (Jammy Jellyfish)\n",
      "Release (kernel)     6.8.0-87-generic\n",
      "Arquitetura          x86_64\n",
      "Distribuição         Ubuntu\n",
      "\n",
      "------------- Sobre o Hardware -------------\n",
      "\n",
      "Processador:\n",
      "  • Modelo           Intel(R) Core(TM) i7-5557U CPU @ 3.10GHz\n",
      "  • CPUs lógicas     4\n",
      "  • Clock base       3392.169 MHz\n",
      "\n",
      "Cache:\n",
      "  • L1d              32 kB\n",
      "  • L1i              32 kB\n",
      "  • L2               256 kB\n",
      "  • L3               4096 kB\n",
      "\n",
      "Memória RAM:\n",
      "  • Total            16260572 kB\n",
      "  • Livre            8203668 kB\n",
      "  • Disponível       11215072 kB\n",
      "\n",
      "Disco:\n",
      "  • Total            108.98 GB\n",
      "  • Usado            69.98 GB\n",
      "  • Livre            33.43 GB\n"
     ]
    }
   ],
   "source": [
    "mostrarSoInfo()\n",
    "mostrarHardwareInfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777d7b9b",
   "metadata": {},
   "source": [
    "### Tarefa 2 - Verificação de parâmetros de armazenamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1bacea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permite que os acessos de hdparm sejam feitos sem sudo\n",
    "# sudo visudo\n",
    "# seu_usuario ALL=(ALL) NOPASSWD: /sbin/hdparm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4741aa14",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = \"/sys/block\"\n",
    "\n",
    "def run(cmd):\n",
    "    return subprocess.check_output(cmd, capture_output=True, text=True).strip()\n",
    "\n",
    "def getDispositivo():\n",
    "    for dev in os.listdir(BASE):\n",
    "        if dev.startswith((\"loop\", \"ram\", \"dm-\")): # ignora\n",
    "            continue\n",
    "        return dev # encontra dispositivo\n",
    "    return None\n",
    "\n",
    "def ehHD(dispositivo):\n",
    "    rotational_path = os.path.join(BASE, dispositivo, \"queue/rotational\")\n",
    "    \n",
    "    if os.path.exists(rotational_path):\n",
    "        with open(rotational_path) as f:\n",
    "            return f.read().strip() == \"1\"\n",
    "    return False\n",
    "\n",
    "def blocos(dispositivo):\n",
    "    cmd = f\"cat /sys/block/{dispositivo}/queue/logical_block_size\"\n",
    "    print(\"Blocos Lógicos:\", run(cmd.split()))\n",
    "\n",
    "    cmd = f\"cat /sys/block/sdX/queue/physical_b\"\n",
    "    print(\"Blcocos Físicos: \", run(cmd.split()))\n",
    "\n",
    "def info(dispositivo):\n",
    "    cmd = f\"sudo hdparm -I /dev/{dispositivo}\"\n",
    "    print(run(cmd.split()))\n",
    "\n",
    "def stat(dispositivo):\n",
    "    cmd = f\"stat -f /dev/{dispositivo}\"\n",
    "    print(\"Parâmetros do SO para o disco:\\n\")\n",
    "    print(run(cmd.split()))\n",
    "\n",
    "def mostrarDiscoInfo():\n",
    "    disp = getDispositivo()\n",
    "    print(\"Tipos de dispositivo:\", \"HD\" if ehHD(disp) else \"SSD\")\n",
    "    print(\"Modelo\", run([\"cat\", f\"/sys/block/{disp}/device/model\"]))\n",
    "    #info(disp)\n",
    "    stat(disp)\n",
    "    blocos(disp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2be8daa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sdb\n",
      "Dispositivo de armazenamento é um SSD.\n"
     ]
    }
   ],
   "source": [
    "disp = getDispositivo()\n",
    "print(disp)\n",
    "if ehHD(disp):\n",
    "    mostrarDiscoInfo()\n",
    "else:\n",
    "    print(\"Dispositivo de armazenamento é um SSD.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969797c6",
   "metadata": {},
   "source": [
    "### Tarefa 3 – Geração de um BD para testes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3051d2",
   "metadata": {},
   "source": [
    "\n",
    "Necessário dar permissão de escrita para a pasta _tpch4pgsql_:\n",
    "\n",
    "``chmod -R u+rwX,g+rwX,o+rX .``"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fe2249",
   "metadata": {},
   "source": [
    "#### Preparar\n",
    "A fase de preparação compila o TPC-H dbgen e querygen e cria os arquivos de carga e atualização (atualização/exclusão)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08f0b8b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/desktoop2/repos/Banco-de-Dados-2025-2/Trabalho 3/tpch4pgsql'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ad2b32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make: Nothing to be done for 'all'.\n",
      "built dbgen from source\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPC-H Population Generator (Version 2.14.0)\n",
      "Copyright Transaction Processing Performance Council 1994 - 2010\n",
      "Generating data for suppliers table\n",
      "Preloading text ...                                                                                                                                                                                                                                                                                                              1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 91010101010101010\n",
      "done.\n",
      "Generating data for customers tabledone.\n",
      "Generating data for orders/lineitem tablesdone.\n",
      "Generating data for part/partsupplier tablesdone.\n",
      "Generating data for nation tabledone.\n",
      "Generating data for region tabledone.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated data for the load phase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPC-H Population Generator (Version 2.14.0)\n",
      "Copyright Transaction Processing Performance Council 1994 - 2010\n",
      "Generating update pair #1 for orders/lineitem tables\n",
      "Preloading text ...                                                                                                                                                                                                                                                                                                              1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 91010101010101010\n",
      "done.\n",
      "Generating update pair #2 for orders/lineitem tablesdone.\n",
      "Generating update pair #3 for orders/lineitem tablesdone.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated data for the update phase\n",
      "generated data for the delete phase\n",
      "created data files in ./data\n",
      "created query files in ./query_root\n"
     ]
    }
   ],
   "source": [
    "tpch_pgsql(phase=\"prepare\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f267c36",
   "metadata": {},
   "source": [
    "#### Carregamento\n",
    "\n",
    "A fase de carregamento (load) limpa o banco de dados (se necessário), carrega as tabelas no banco de dados e cria índices para consultas. Os resultados desta fase consistem nas seguintes métricas:\n",
    "\n",
    "* Tempo de criação do esquema\n",
    "* Tempo de carregamento dos dados\n",
    "* Tempo de criação de restrições de chave estrangeira e índices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd988054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropped existing tables\n",
      "cleaned database tpch\n",
      "done creating schemas\n",
      "done loading data to tables\n",
      "done creating indexes and foreign keys\n",
      "============================================================\n",
      "=========================== Load ===========================\n",
      "============================================================\n",
      "create_schema: : 0:00:00.089756\n",
      "load_data: 0:01:21.703898\n",
      "index_tables: 0:01:19.943115\n",
      "============================================================\n",
      "======================= End Results ========================\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "tpch_pgsql(phase=\"load\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f2707b",
   "metadata": {},
   "source": [
    "#### Consultas\n",
    "\n",
    "Nessa fase, as consultas serão analizadas com o comando ``EXPLAIN ANALYZE``, evidenciando:\n",
    "\n",
    "* Tempo de execução do planejamento;\n",
    "* Tempo de execução do _exlpain_;\n",
    "* Algoritmos utilizados.\n",
    "\n",
    "Em seguida, as consultas serão executas, exibindo as seguintes informações:\n",
    "\n",
    "* Até 10 linhas do resultado da consulta;\n",
    "* Total de linhas encontradas;\n",
    "* Tempo de execução."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4fb597c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PGDBWithResults(pgdb.PGDB):\n",
    "\n",
    "    def __init__(self, host, port, database, user, password):\n",
    "        # Chamar o construtor da classe pai corretamente\n",
    "        self.conn = psycopg2.connect(\n",
    "                    host=host,\n",
    "                    port=port,\n",
    "                    dbname=database,\n",
    "                    user=user,\n",
    "                    password=password\n",
    "                ) \n",
    "        if hasattr(self, 'conn') and self.conn:\n",
    "            print(\"Conexão estabelecida com sucesso!\")\n",
    "        else:\n",
    "            print(\"Atenção: Conexão não estabelecida\")\n",
    "    \n",
    "    def executeQueryFromFileWithResults(self, filepath):\n",
    "        \"\"\"Executa query de arquivo e retorna resultados\"\"\"\n",
    "        try:\n",
    "            # Verificar se a conexão existe\n",
    "            if not hasattr(self, 'conn') or not self.conn:\n",
    "                return {'error': 'Conexão não disponível'}\n",
    "            \n",
    "            with open(filepath, 'r') as f:\n",
    "                query = f.read()\n",
    "            \n",
    "            # Usar cursor que retorna dicionários\n",
    "            with self.conn.cursor(cursor_factory=RealDictCursor) as cursor:\n",
    "                cursor.execute(query)\n",
    "                \n",
    "                if cursor.description:  # Se é uma query SELECT\n",
    "                    results = cursor.fetchall()\n",
    "                    columns = [desc[0] for desc in cursor.description]\n",
    "                    return {\n",
    "                        'columns': columns,\n",
    "                        'data': results,\n",
    "                        'rowcount': cursor.rowcount\n",
    "                    }\n",
    "                else:  # Para INSERT, UPDATE, DELETE\n",
    "                    return {\n",
    "                        'rowcount': cursor.rowcount,\n",
    "                        'message': f\"Query executada: {cursor.rowcount} linhas afetadas\"\n",
    "                    }\n",
    "                    \n",
    "        except Exception as e:\n",
    "            return {'error': str(e)}\n",
    "        \n",
    "    def executeQuery(self, query_string):\n",
    "        \"\"\"Executa uma query diretamente a partir de string\"\"\"\n",
    "        try:\n",
    "            if not self.conn:\n",
    "                return {'error': 'Conexão não disponível'}\n",
    "            \n",
    "            with self.conn.cursor(cursor_factory=RealDictCursor) as cursor:\n",
    "                cursor.execute(query_string)\n",
    "                \n",
    "                if cursor.description:  # Se é uma query SELECT\n",
    "                    results = cursor.fetchall()\n",
    "                    columns = [desc[0] for desc in cursor.description]\n",
    "                    return {\n",
    "                        'columns': columns,\n",
    "                        'data': results,\n",
    "                        'rowcount': cursor.rowcount\n",
    "                    }\n",
    "                else:  # Para INSERT, UPDATE, DELETE\n",
    "                    self.conn.commit()\n",
    "                    return {\n",
    "                        'rowcount': cursor.rowcount,\n",
    "                        'message': f\"Query executada: {cursor.rowcount} linhas afetadas\"\n",
    "                    }\n",
    "                    \n",
    "        except Exception as e:\n",
    "            return {'error': str(e)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd991ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conexão estabelecida com sucesso!\n",
      "\n",
      "========================================================================================================================\n",
      "EXPLAIN ANALYZE - QUERY 1\n",
      "========================================================================================================================\n",
      "\n",
      "Tempo de execução do EXPLAIN: 0:00:05.978654\n",
      "\n",
      "PLANO DE EXECUÇÃO (EXPLAIN ANALYZE):\n",
      "Limit  (cost=346387.38..346388.51 rows=1 width=248) (actual time=4466.338..5925.241 rows=1 loops=1)\n",
      "  ->  Finalize GroupAggregate  (cost=346387.38..391477.69 rows=40000 width=248) (actual time=4432.749..5891.650 rows=1 loops=1)\n",
      "        Group Key: l_returnflag, l_linestatus\n",
      "        ->  Gather Merge  (cost=346387.38..387777.69 rows=80000 width=248) (actual time=4398.819..5891.549 rows=4 loops=1)\n",
      "              Workers Planned: 2\n",
      "              Workers Launched: 2\n",
      "              ->  Partial GroupAggregate  (cost=345387.36..377543.68 rows=40000 width=248) (actual time=4086.164..5203.529 rows=3 loops=3)\n",
      "                    Group Key: l_returnflag, l_linestatus\n",
      "                    ->  Sort  (cost=345387.36..347471.11 rows=833502 width=144) (actual time=2874.367..3319.906 rows=1135394 loops=3)\n",
      "                          Sort Key: l_returnflag, l_linestatus\n",
      "                          Sort Method: external merge  Disk: 77240kB\n",
      "                          Worker 0:  Sort Method: external merge  Disk: 62824kB\n",
      "                          Worker 1:  Sort Method: external merge  Disk: 76344kB\n",
      "                          ->  Parallel Seq Scan on lineitem  (cost=0.00..143759.33 rows=833502 width=144) (actual time=25.684..841.528 rows=1977551 loops=3)\n",
      "                                Filter: (l_shipdate <= '1998-09-11 00:00:00'::timestamp without time zone)\n",
      "                                Rows Removed by Filter: 22854\n",
      "Planning Time: 1.624 ms\n",
      "JIT:\n",
      "  Functions: 31\n",
      "  Options: Inlining false, Optimization false, Expressions true, Deforming true\n",
      "  Timing: Generation 8.143 ms, Inlining 0.000 ms, Optimization 2.759 ms, Emission 107.936 ms, Total 118.837 ms\n",
      "Execution Time: 5968.538 ms\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "ALGORITMOS IDENTIFICADOS NO PLANO DE EXECUÇÃO:\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Algoritmos de Varredura: Seq Scan\n",
      "Algoritmos de Ordenação: Sort\n",
      "Algoritmos de Agregação: GroupAggregate\n",
      "\n",
      "========================================================================================================================\n",
      "EXPLAIN ANALYZE - QUERY 3\n",
      "========================================================================================================================\n",
      "\n",
      "Tempo de execução do EXPLAIN: 0:00:01.309687\n",
      "\n",
      "PLANO DE EXECUÇÃO (EXPLAIN ANALYZE):\n",
      "Limit  (cost=187311.61..187311.63 rows=10 width=44) (actual time=1298.564..1306.292 rows=10 loops=1)\n",
      "  ->  Sort  (cost=187311.61..187319.94 rows=3334 width=44) (actual time=1275.911..1283.636 rows=10 loops=1)\n",
      "        Sort Key: (sum((lineitem.l_extendedprice * ('1'::numeric - lineitem.l_discount)))) DESC, orders.o_orderdate\n",
      "        Sort Method: top-N heapsort  Memory: 26kB\n",
      "        ->  Finalize GroupAggregate  (cost=186800.84..187239.56 rows=3334 width=44) (actual time=1235.014..1277.391 rows=11427 loops=1)\n",
      "              Group Key: lineitem.l_orderkey, orders.o_orderdate, orders.o_shippriority\n",
      "              ->  Gather Merge  (cost=186800.84..187163.16 rows=2778 width=44) (actual time=1234.965..1261.362 rows=11441 loops=1)\n",
      "                    Workers Planned: 2\n",
      "                    Workers Launched: 2\n",
      "                    ->  Partial GroupAggregate  (cost=185800.82..185842.49 rows=1389 width=44) (actual time=1206.306..1219.999 rows=3814 loops=3)\n",
      "                          Group Key: lineitem.l_orderkey, orders.o_orderdate, orders.o_shippriority\n",
      "                          ->  Sort  (cost=185800.82..185804.29 rows=1389 width=76) (actual time=1206.185..1207.180 rows=10088 loops=3)\n",
      "                                Sort Key: lineitem.l_orderkey, orders.o_orderdate, orders.o_shippriority\n",
      "                                Sort Method: quicksort  Memory: 1277kB\n",
      "                                Worker 0:  Sort Method: quicksort  Memory: 1083kB\n",
      "                                Worker 1:  Sort Method: quicksort  Memory: 1158kB\n",
      "                                ->  Parallel Hash Join  (cost=38837.56..185728.31 rows=1389 width=76) (actual time=290.451..1192.317 rows=10088 loops=3)\n",
      "                                      Hash Cond: (lineitem.l_orderkey = orders.o_orderkey)\n",
      "                                      ->  Parallel Seq Scan on lineitem  (cost=0.00..143759.33 rows=833502 width=68) (actual time=0.047..679.300 rows=1084764 loops=3)\n",
      "                                            Filter: (l_shipdate > '1995-03-10'::date)\n",
      "                                            Rows Removed by Filter: 915641\n",
      "                                      ->  Parallel Hash  (cost=38824.54..38824.54 rows=1042 width=12) (actual time=289.992..290.001 rows=48171 loops=3)\n",
      "                                            Buckets: 262144 (originally 4096)  Batches: 1 (originally 1)  Memory Usage: 10912kB\n",
      "                                            ->  Parallel Hash Join  (cost=4370.15..38824.54 rows=1042 width=12) (actual time=49.469..256.509 rows=48171 loops=3)\n",
      "                                                  Hash Cond: (orders.o_custkey = customer.c_custkey)\n",
      "                                                  ->  Parallel Seq Scan on orders  (cost=0.00..33907.50 rows=208333 width=16) (actual time=0.049..127.220 rows=241374 loops=3)\n",
      "                                                        Filter: (o_orderdate < '1995-03-10'::date)\n",
      "                                                        Rows Removed by Filter: 258626\n",
      "                                                  ->  Parallel Hash  (cost=4366.25..4366.25 rows=312 width=4) (actual time=49.354..49.357 rows=10063 loops=3)\n",
      "                                                        Buckets: 32768 (originally 1024)  Batches: 1 (originally 1)  Memory Usage: 1752kB\n",
      "                                                        ->  Parallel Seq Scan on customer  (cost=0.00..4366.25 rows=312 width=4) (actual time=24.284..36.440 rows=10063 loops=3)\n",
      "                                                              Filter: (c_mktsegment = 'HOUSEHOLD'::bpchar)\n",
      "                                                              Rows Removed by Filter: 39937\n",
      "Planning Time: 0.516 ms\n",
      "JIT:\n",
      "  Functions: 94\n",
      "  Options: Inlining false, Optimization false, Expressions true, Deforming true\n",
      "  Timing: Generation 10.234 ms, Inlining 0.000 ms, Optimization 5.204 ms, Emission 90.499 ms, Total 105.937 ms\n",
      "Execution Time: 1307.856 ms\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "ALGORITMOS IDENTIFICADOS NO PLANO DE EXECUÇÃO:\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Algoritmos de Junção: Hash Join\n",
      "Algoritmos de Varredura: Seq Scan\n",
      "Algoritmos de Ordenação: Sort\n",
      "Algoritmos de Agregação: GroupAggregate\n",
      "\n",
      "========================================================================================================================\n",
      "EXPLAIN ANALYZE - QUERY 5\n",
      "========================================================================================================================\n",
      "\n",
      "Tempo de execução do EXPLAIN: 0:00:01.733663\n",
      "\n",
      "PLANO DE EXECUÇÃO (EXPLAIN ANALYZE):\n",
      "Limit  (cost=185541.66..185541.66 rows=1 width=136) (actual time=1720.642..1723.648 rows=1 loops=1)\n",
      "  ->  Sort  (cost=185541.66..185541.72 rows=25 width=136) (actual time=1692.826..1695.830 rows=1 loops=1)\n",
      "        Sort Key: (sum((lineitem.l_extendedprice * ('1'::numeric - lineitem.l_discount)))) DESC\n",
      "        Sort Method: top-N heapsort  Memory: 25kB\n",
      "        ->  Finalize GroupAggregate  (cost=185537.97..185541.54 rows=25 width=136) (actual time=1691.528..1695.794 rows=5 loops=1)\n",
      "              Group Key: nation.n_name\n",
      "              ->  Gather Merge  (cost=185537.97..185541.04 rows=24 width=136) (actual time=1691.130..1695.728 rows=15 loops=1)\n",
      "                    Workers Planned: 2\n",
      "                    Workers Launched: 2\n",
      "                    ->  Partial GroupAggregate  (cost=184537.95..184538.25 rows=12 width=136) (actual time=1651.700..1653.192 rows=5 loops=3)\n",
      "                          Group Key: nation.n_name\n",
      "                          ->  Sort  (cost=184537.95..184537.98 rows=12 width=168) (actual time=1651.225..1651.510 rows=2402 loops=3)\n",
      "                                Sort Key: nation.n_name\n",
      "                                Sort Method: quicksort  Memory: 292kB\n",
      "                                Worker 0:  Sort Method: quicksort  Memory: 287kB\n",
      "                                Worker 1:  Sort Method: quicksort  Memory: 274kB\n",
      "                                ->  Hash Join  (cost=39517.10..184537.73 rows=12 width=168) (actual time=244.367..1647.784 rows=2402 loops=3)\n",
      "                                      Hash Cond: ((orders.o_custkey = customer.c_custkey) AND (supplier.s_nationkey = customer.c_nationkey))\n",
      "                                      ->  Hash Join  (cost=35956.06..180060.80 rows=12502 width=72) (actual time=164.760..1367.422 rows=304642 loops=3)\n",
      "                                            Hash Cond: (lineitem.l_suppkey = supplier.s_suppkey)\n",
      "                                            ->  Parallel Hash Join  (cost=35509.06..179580.98 rows=12502 width=72) (actual time=158.836..1181.119 rows=304642 loops=3)\n",
      "                                                  Hash Cond: (lineitem.l_orderkey = orders.o_orderkey)\n",
      "                                                  ->  Parallel Seq Scan on lineitem  (cost=0.00..137508.06 rows=2500506 width=72) (actual time=0.062..468.657 rows=2000405 loops=3)\n",
      "                                                  ->  Parallel Hash  (cost=35470.00..35470.00 rows=3125 width=8) (actual time=157.851..157.854 rows=76212 loops=3)\n",
      "                                                        Buckets: 262144 (originally 8192)  Batches: 1 (originally 1)  Memory Usage: 13024kB\n",
      "                                                        ->  Parallel Seq Scan on orders  (cost=0.00..35470.00 rows=3125 width=8) (actual time=0.096..118.155 rows=76212 loops=3)\n",
      "                                                              Filter: ((o_orderdate >= '1995-01-01'::date) AND (o_orderdate < '1996-01-01 00:00:00'::timestamp without time zone))\n",
      "                                                              Rows Removed by Filter: 423788\n",
      "                                            ->  Hash  (cost=322.00..322.00 rows=10000 width=8) (actual time=5.789..5.790 rows=10000 loops=3)\n",
      "                                                  Buckets: 16384  Batches: 1  Memory Usage: 519kB\n",
      "                                                  ->  Seq Scan on supplier  (cost=0.00..322.00 rows=10000 width=8) (actual time=0.064..2.658 rows=10000 loops=3)\n",
      "                                      ->  Hash  (cost=2583.03..2583.03 rows=30000 width=116) (actual time=77.813..77.819 rows=29764 loops=3)\n",
      "                                            Buckets: 32768  Batches: 2  Memory Usage: 1313kB\n",
      "                                            ->  Nested Loop  (cost=9.79..2583.03 rows=30000 width=116) (actual time=29.999..64.320 rows=29764 loops=3)\n",
      "                                                  ->  Nested Loop  (cost=0.00..2.62 rows=5 width=108) (actual time=28.895..28.920 rows=5 loops=3)\n",
      "                                                        Join Filter: (nation.n_regionkey = region.r_regionkey)\n",
      "                                                        Rows Removed by Join Filter: 20\n",
      "                                                        ->  Seq Scan on region  (cost=0.00..1.06 rows=1 width=4) (actual time=28.848..28.852 rows=1 loops=3)\n",
      "                                                              Filter: (r_name = 'AFRICA'::bpchar)\n",
      "                                                              Rows Removed by Filter: 4\n",
      "                                                        ->  Seq Scan on nation  (cost=0.00..1.25 rows=25 width=112) (actual time=0.024..0.032 rows=25 loops=3)\n",
      "                                                  ->  Bitmap Heap Scan on customer  (cost=9.79..508.58 rows=750 width=8) (actual time=1.161..6.100 rows=5953 loops=15)\n",
      "                                                        Recheck Cond: (c_nationkey = nation.n_nationkey)\n",
      "                                                        Heap Blocks: exact=14642\n",
      "                                                        ->  Bitmap Index Scan on idx_customer_nationkey  (cost=0.00..9.60 rows=750 width=0) (actual time=0.690..0.690 rows=5953 loops=15)\n",
      "                                                              Index Cond: (c_nationkey = nation.n_nationkey)\n",
      "Planning Time: 4.854 ms\n",
      "JIT:\n",
      "  Functions: 142\n",
      "  Options: Inlining false, Optimization false, Expressions true, Deforming true\n",
      "  Timing: Generation 7.877 ms, Inlining 0.000 ms, Optimization 6.494 ms, Emission 108.464 ms, Total 122.835 ms\n",
      "Execution Time: 1726.542 ms\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "ALGORITMOS IDENTIFICADOS NO PLANO DE EXECUÇÃO:\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Algoritmos de Junção: Hash Join, Nested Loop\n",
      "Algoritmos de Varredura: Seq Scan, Bitmap Heap Scan, Index Scan, Bitmap Index Scan\n",
      "Algoritmos de Ordenação: Sort\n",
      "Algoritmos de Agregação: GroupAggregate\n",
      "\n",
      "========================================================================================================================\n",
      "EXPLAIN ANALYZE - QUERY 6\n",
      "========================================================================================================================\n",
      "\n",
      "Tempo de execução do EXPLAIN: 0:00:00.824284\n",
      "\n",
      "PLANO DE EXECUÇÃO (EXPLAIN ANALYZE):\n",
      "Limit  (cost=169764.72..169764.73 rows=1 width=32) (actual time=809.725..822.040 rows=1 loops=1)\n",
      "  ->  Finalize Aggregate  (cost=169764.72..169764.73 rows=1 width=32) (actual time=795.255..807.569 rows=1 loops=1)\n",
      "        ->  Gather  (cost=169764.50..169764.71 rows=2 width=32) (actual time=794.864..807.537 rows=3 loops=1)\n",
      "              Workers Planned: 2\n",
      "              Workers Launched: 2\n",
      "              ->  Partial Aggregate  (cost=168764.50..168764.51 rows=1 width=32) (actual time=769.255..769.256 rows=1 loops=3)\n",
      "                    ->  Parallel Seq Scan on lineitem  (cost=0.00..168764.39 rows=21 width=64) (actual time=11.792..744.764 rows=40011 loops=3)\n",
      "                          Filter: ((l_shipdate >= '1995-01-01'::date) AND (l_shipdate < '1996-01-01 00:00:00'::timestamp without time zone) AND (l_discount >= 0.03) AND (l_discount <= 0.05) AND (l_quantity < '25'::numeric))\n",
      "                          Rows Removed by Filter: 1960394\n",
      "Planning Time: 0.115 ms\n",
      "JIT:\n",
      "  Functions: 18\n",
      "  Options: Inlining false, Optimization false, Expressions true, Deforming true\n",
      "  Timing: Generation 6.193 ms, Inlining 0.000 ms, Optimization 1.922 ms, Emission 47.598 ms, Total 55.713 ms\n",
      "Execution Time: 823.005 ms\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "ALGORITMOS IDENTIFICADOS NO PLANO DE EXECUÇÃO:\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Algoritmos de Varredura: Seq Scan\n",
      "\n",
      "========================================================================================================================\n",
      "EXPLAIN ANALYZE - QUERY 7\n",
      "========================================================================================================================\n",
      "\n",
      "Tempo de execução do EXPLAIN: 0:00:01.365339\n",
      "\n",
      "PLANO DE EXECUÇÃO (EXPLAIN ANALYZE):\n",
      "Limit  (cost=151367.99..151470.65 rows=1 width=272) (actual time=1344.576..1354.559 rows=1 loops=1)\n",
      "  ->  GroupAggregate  (cost=151367.99..161634.84 rows=100 width=272) (actual time=1300.208..1310.191 rows=1 loops=1)\n",
      "        Group Key: n1.n_name, n2.n_name, EXTRACT(year FROM lineitem.l_shipdate)\n",
      "        ->  Nested Loop  (cost=151367.99..161631.84 rows=100 width=304) (actual time=898.426..1307.342 rows=1418 loops=1)\n",
      "              Join Filter: (n2.n_nationkey = customer.c_nationkey)\n",
      "              Rows Removed by Join Filter: 35067\n",
      "              ->  Nested Loop  (cost=151367.57..160481.31 rows=2497 width=284) (actual time=898.159..1168.162 rows=36485 loops=1)\n",
      "                    ->  Gather Merge  (cost=151367.14..151657.95 rows=2497 width=284) (actual time=898.090..937.688 rows=36485 loops=1)\n",
      "                          Workers Planned: 2\n",
      "                          Workers Launched: 2\n",
      "                          ->  Sort  (cost=150367.11..150369.71 rows=1040 width=284) (actual time=865.824..874.168 rows=12499 loops=3)\n",
      "                                Sort Key: n1.n_name, n2.n_name, (EXTRACT(year FROM lineitem.l_shipdate))\n",
      "                                Sort Method: external merge  Disk: 4360kB\n",
      "                                Worker 0:  Sort Method: external merge  Disk: 4528kB\n",
      "                                Worker 1:  Sort Method: external merge  Disk: 4368kB\n",
      "                                ->  Hash Join  (cost=247.12..150315.00 rows=1040 width=284) (actual time=24.528..778.053 rows=47880 loops=3)\n",
      "                                      Hash Cond: (lineitem.l_suppkey = supplier.s_suppkey)\n",
      "                                      ->  Parallel Seq Scan on lineitem  (cost=0.00..150010.59 rows=12502 width=76) (actual time=23.196..637.127 rows=609483 loops=3)\n",
      "                                            Filter: ((l_shipdate >= '1995-01-01'::date) AND (l_shipdate <= '1996-12-31'::date))\n",
      "                                            Rows Removed by Filter: 1390922\n",
      "                                      ->  Hash  (cost=236.72..236.72 rows=832 width=216) (actual time=1.161..1.164 rows=786 loops=3)\n",
      "                                            Buckets: 1024  Batches: 1  Memory Usage: 79kB\n",
      "                                            ->  Nested Loop  (cost=4.67..236.72 rows=832 width=216) (actual time=0.157..0.942 rows=786 loops=3)\n",
      "                                                  ->  Nested Loop  (cost=0.00..2.84 rows=2 width=216) (actual time=0.061..0.077 rows=2 loops=3)\n",
      "                                                        Join Filter: (((n1.n_name = 'GERMANY'::bpchar) AND (n2.n_name = 'UNITED KINGDOM'::bpchar)) OR ((n1.n_name = 'UNITED KINGDOM'::bpchar) AND (n2.n_name = 'GERMANY'::bpchar)))\n",
      "                                                        Rows Removed by Join Filter: 2\n",
      "                                                        ->  Seq Scan on nation n1  (cost=0.00..1.38 rows=2 width=108) (actual time=0.036..0.042 rows=2 loops=3)\n",
      "                                                              Filter: ((n_name = 'GERMANY'::bpchar) OR (n_name = 'UNITED KINGDOM'::bpchar))\n",
      "                                                              Rows Removed by Filter: 23\n",
      "                                                        ->  Materialize  (cost=0.00..1.39 rows=2 width=108) (actual time=0.007..0.011 rows=2 loops=6)\n",
      "                                                              ->  Seq Scan on nation n2  (cost=0.00..1.38 rows=2 width=108) (actual time=0.010..0.016 rows=2 loops=3)\n",
      "                                                                    Filter: ((n_name = 'UNITED KINGDOM'::bpchar) OR (n_name = 'GERMANY'::bpchar))\n",
      "                                                                    Rows Removed by Filter: 23\n",
      "                                                  ->  Bitmap Heap Scan on supplier  (cost=4.67..116.44 rows=50 width=8) (actual time=0.074..0.372 rows=393 loops=6)\n",
      "                                                        Recheck Cond: (s_nationkey = n1.n_nationkey)\n",
      "                                                        Heap Blocks: exact=381\n",
      "                                                        ->  Bitmap Index Scan on idx_supplier_nation_key  (cost=0.00..4.66 rows=50 width=0) (actual time=0.046..0.047 rows=393 loops=6)\n",
      "                                                              Index Cond: (s_nationkey = n1.n_nationkey)\n",
      "                    ->  Index Scan using orders_pkey on orders  (cost=0.43..3.53 rows=1 width=8) (actual time=0.006..0.006 rows=1 loops=36485)\n",
      "                          Index Cond: (o_orderkey = lineitem.l_orderkey)\n",
      "              ->  Index Scan using customer_pkey on customer  (cost=0.42..0.45 rows=1 width=8) (actual time=0.003..0.003 rows=1 loops=36485)\n",
      "                    Index Cond: (c_custkey = orders.o_custkey)\n",
      "Planning Time: 2.391 ms\n",
      "JIT:\n",
      "  Functions: 100\n",
      "  Options: Inlining false, Optimization false, Expressions true, Deforming true\n",
      "  Timing: Generation 9.401 ms, Inlining 0.000 ms, Optimization 4.982 ms, Emission 109.047 ms, Total 123.430 ms\n",
      "Execution Time: 1360.328 ms\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "ALGORITMOS IDENTIFICADOS NO PLANO DE EXECUÇÃO:\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Algoritmos de Junção: Nested Loop, Hash Join\n",
      "Algoritmos de Varredura: Seq Scan, Bitmap Heap Scan, Index Scan, Bitmap Index Scan\n",
      "Algoritmos de Ordenação: Sort\n",
      "Algoritmos de Agregação: GroupAggregate\n",
      "\n",
      "========================================================================================================================\n",
      "EXPLAIN ANALYZE - QUERY 9\n",
      "========================================================================================================================\n",
      "\n",
      "Tempo de execução do EXPLAIN: 0:00:00.511880\n",
      "\n",
      "PLANO DE EXECUÇÃO (EXPLAIN ANALYZE):\n",
      "Limit  (cost=27842.91..27844.21 rows=1 width=168) (actual time=498.523..503.932 rows=1 loops=1)\n",
      "  ->  GroupAggregate  (cost=27842.91..28624.64 rows=600 width=168) (actual time=498.522..503.930 rows=1 loops=1)\n",
      "        Group Key: nation.n_name, (EXTRACT(year FROM orders.o_orderdate))\n",
      "        ->  Incremental Sort  (cost=27842.91..28605.14 rows=600 width=264) (actual time=497.592..503.104 rows=1266 loops=1)\n",
      "              Sort Key: nation.n_name, (EXTRACT(year FROM orders.o_orderdate)) DESC\n",
      "              Presorted Key: nation.n_name\n",
      "              Full-sort Groups: 1  Sort Method: quicksort  Average Memory: 34kB  Peak Memory: 34kB\n",
      "              Pre-sorted Groups: 1  Sort Method: quicksort  Average Memory: 2366kB  Peak Memory: 2366kB\n",
      "              ->  Nested Loop  (cost=27811.51..28573.12 rows=600 width=264) (actual time=274.599..488.833 rows=14092 loops=1)\n",
      "                    ->  Nested Loop  (cost=27811.08..28292.54 rows=600 width=236) (actual time=274.584..368.239 rows=14092 loops=1)\n",
      "                          Join Filter: (supplier.s_suppkey = lineitem.l_suppkey)\n",
      "                          ->  Gather Merge  (cost=27810.65..27819.97 rows=80 width=152) (actual time=274.512..281.536 rows=1858 loops=1)\n",
      "                                Workers Planned: 2\n",
      "                                Workers Launched: 2\n",
      "                                ->  Sort  (cost=26810.63..26810.71 rows=33 width=152) (actual time=249.911..250.103 rows=1139 loops=3)\n",
      "                                      Sort Key: nation.n_name\n",
      "                                      Sort Method: quicksort  Memory: 2201kB\n",
      "                                      Worker 0:  Sort Method: quicksort  Memory: 2500kB\n",
      "                                      Worker 1:  Sort Method: quicksort  Memory: 2605kB\n",
      "                                      ->  Hash Join  (cost=5140.61..26809.79 rows=33 width=152) (actual time=37.688..227.392 rows=14584 loops=3)\n",
      "                                            Hash Cond: (supplier.s_nationkey = nation.n_nationkey)\n",
      "                                            ->  Nested Loop  (cost=5139.05..26808.15 rows=33 width=52) (actual time=37.481..220.309 rows=14584 loops=3)\n",
      "                                                  ->  Parallel Hash Join  (cost=5138.77..26798.12 rows=33 width=44) (actual time=37.437..161.948 rows=14584 loops=3)\n",
      "                                                        Hash Cond: (partsupp.ps_partkey = part.p_partkey)\n",
      "                                                        ->  Parallel Seq Scan on partsupp  (cost=0.00..20784.33 rows=333333 width=40) (actual time=0.023..65.995 rows=266667 loops=3)\n",
      "                                                        ->  Parallel Hash  (cost=5138.67..5138.67 rows=8 width=4) (actual time=37.184..37.184 rows=3646 loops=3)\n",
      "                                                              Buckets: 16384 (originally 1024)  Batches: 1 (originally 1)  Memory Usage: 760kB\n",
      "                                                              ->  Parallel Seq Scan on part  (cost=0.00..5138.67 rows=8 width=4) (actual time=0.022..29.269 rows=3646 loops=3)\n",
      "                                                                    Filter: ((p_name)::text ~~ '%lavender%'::text)\n",
      "                                                                    Rows Removed by Filter: 63021\n",
      "                                                  ->  Index Scan using supplier_pkey on supplier  (cost=0.29..0.30 rows=1 width=8) (actual time=0.003..0.003 rows=1 loops=43752)\n",
      "                                                        Index Cond: (s_suppkey = partsupp.ps_suppkey)\n",
      "                                            ->  Hash  (cost=1.25..1.25 rows=25 width=108) (actual time=0.031..0.031 rows=25 loops=3)\n",
      "                                                  Buckets: 1024  Batches: 1  Memory Usage: 10kB\n",
      "                                                  ->  Seq Scan on nation  (cost=0.00..1.25 rows=25 width=108) (actual time=0.016..0.020 rows=25 loops=3)\n",
      "                          ->  Index Scan using idx_lineitem_part_supp on lineitem  (cost=0.43..4.03 rows=150 width=108) (actual time=0.012..0.043 rows=8 loops=1858)\n",
      "                                Index Cond: ((l_partkey = partsupp.ps_partkey) AND (l_suppkey = partsupp.ps_suppkey))\n",
      "                    ->  Index Scan using orders_pkey on orders  (cost=0.43..0.47 rows=1 width=8) (actual time=0.008..0.008 rows=1 loops=14092)\n",
      "                          Index Cond: (o_orderkey = lineitem.l_orderkey)\n",
      "Planning Time: 4.617 ms\n",
      "Execution Time: 504.126 ms\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "ALGORITMOS IDENTIFICADOS NO PLANO DE EXECUÇÃO:\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Algoritmos de Junção: Nested Loop, Hash Join\n",
      "Algoritmos de Varredura: Seq Scan, Index Scan\n",
      "Algoritmos de Ordenação: Sort, Incremental Sort\n",
      "Algoritmos de Agregação: GroupAggregate\n",
      "\n",
      "========================================================================================================================\n",
      "EXPLAIN ANALYZE - QUERY 10\n",
      "========================================================================================================================\n",
      "\n",
      "Tempo de execução do EXPLAIN: 0:00:01.349321\n",
      "\n",
      "PLANO DE EXECUÇÃO (EXPLAIN ANALYZE):\n",
      "Limit  (cost=180487.29..180487.34 rows=20 width=654) (actual time=1335.249..1341.417 rows=20 loops=1)\n",
      "  ->  Sort  (cost=180487.29..180487.66 rows=150 width=654) (actual time=1301.111..1307.276 rows=20 loops=1)\n",
      "        Sort Key: (sum((lineitem.l_extendedprice * ('1'::numeric - lineitem.l_discount)))) DESC\n",
      "        Sort Method: top-N heapsort  Memory: 34kB\n",
      "        ->  Finalize GroupAggregate  (cost=180464.16..180483.29 rows=150 width=654) (actual time=1161.250..1288.454 rows=37880 loops=1)\n",
      "              Group Key: customer.c_custkey, nation.n_name\n",
      "              ->  Gather Merge  (cost=180464.16..180480.18 rows=124 width=654) (actual time=1161.166..1234.035 rows=44971 loops=1)\n",
      "                    Workers Planned: 2\n",
      "                    Workers Launched: 2\n",
      "                    ->  Partial GroupAggregate  (cost=179464.14..179465.84 rows=62 width=654) (actual time=1123.809..1177.489 rows=14990 loops=3)\n",
      "                          Group Key: customer.c_custkey, nation.n_name\n",
      "                          ->  Sort  (cost=179464.14..179464.29 rows=62 width=686) (actual time=1123.744..1133.447 rows=38169 loops=3)\n",
      "                                Sort Key: customer.c_custkey, nation.n_name\n",
      "                                Sort Method: external merge  Disk: 6952kB\n",
      "                                Worker 0:  Sort Method: external merge  Disk: 7880kB\n",
      "                                Worker 1:  Sort Method: external merge  Disk: 7096kB\n",
      "                                ->  Hash Join  (cost=35511.04..179462.29 rows=62 width=686) (actual time=161.812..1062.677 rows=38169 loops=3)\n",
      "                                      Hash Cond: (customer.c_nationkey = nation.n_nationkey)\n",
      "                                      ->  Nested Loop  (cost=35509.48..179460.57 rows=62 width=586) (actual time=137.425..1021.363 rows=38169 loops=3)\n",
      "                                            ->  Parallel Hash Join  (cost=35509.06..179301.21 rows=62 width=68) (actual time=137.356..845.317 rows=38169 loops=3)\n",
      "                                                  Hash Cond: (lineitem.l_orderkey = orders.o_orderkey)\n",
      "                                                  ->  Parallel Seq Scan on lineitem  (cost=0.00..143759.33 rows=12502 width=68) (actual time=0.058..586.484 rows=492957 loops=3)\n",
      "                                                        Filter: (l_returnflag = 'R'::bpchar)\n",
      "                                                        Rows Removed by Filter: 1507448\n",
      "                                                  ->  Parallel Hash  (cost=35470.00..35470.00 rows=3125 width=8) (actual time=136.537..136.538 rows=19031 loops=3)\n",
      "                                                        Buckets: 65536 (originally 8192)  Batches: 1 (originally 1)  Memory Usage: 3232kB\n",
      "                                                        ->  Parallel Seq Scan on orders  (cost=0.00..35470.00 rows=3125 width=8) (actual time=0.050..125.008 rows=19031 loops=3)\n",
      "                                                              Filter: ((o_orderdate >= '1993-05-01'::date) AND (o_orderdate < '1993-08-01 00:00:00'::timestamp without time zone))\n",
      "                                                              Rows Removed by Filter: 480969\n",
      "                                            ->  Index Scan using customer_pkey on customer  (cost=0.42..2.57 rows=1 width=522) (actual time=0.004..0.004 rows=1 loops=114508)\n",
      "                                                  Index Cond: (c_custkey = orders.o_custkey)\n",
      "                                      ->  Hash  (cost=1.25..1.25 rows=25 width=108) (actual time=24.348..24.348 rows=25 loops=3)\n",
      "                                            Buckets: 1024  Batches: 1  Memory Usage: 10kB\n",
      "                                            ->  Seq Scan on nation  (cost=0.00..1.25 rows=25 width=108) (actual time=24.306..24.313 rows=25 loops=3)\n",
      "Planning Time: 0.795 ms\n",
      "JIT:\n",
      "  Functions: 103\n",
      "  Options: Inlining false, Optimization false, Expressions true, Deforming true\n",
      "  Timing: Generation 8.478 ms, Inlining 0.000 ms, Optimization 3.470 ms, Emission 103.854 ms, Total 115.802 ms\n",
      "Execution Time: 1346.956 ms\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "ALGORITMOS IDENTIFICADOS NO PLANO DE EXECUÇÃO:\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Algoritmos de Junção: Hash Join, Nested Loop\n",
      "Algoritmos de Varredura: Seq Scan, Index Scan\n",
      "Algoritmos de Ordenação: Sort\n",
      "Algoritmos de Agregação: GroupAggregate\n",
      "\n",
      "========================================================================================================================\n",
      "EXPLAIN ANALYZE - QUERY 12\n",
      "========================================================================================================================\n",
      "\n",
      "Tempo de execução do EXPLAIN: 0:00:01.093296\n",
      "\n",
      "PLANO DE EXECUÇÃO (EXPLAIN ANALYZE):\n",
      "Limit  (cost=169882.91..169883.05 rows=1 width=60) (actual time=1086.124..1090.452 rows=1 loops=1)\n",
      "  ->  Finalize GroupAggregate  (cost=169882.91..169887.07 rows=30 width=60) (actual time=1069.851..1074.179 rows=1 loops=1)\n",
      "        Group Key: lineitem.l_shipmode\n",
      "        ->  Gather Merge  (cost=169882.91..169886.56 rows=28 width=60) (actual time=1067.097..1074.144 rows=4 loops=1)\n",
      "              Workers Planned: 2\n",
      "              Workers Launched: 2\n",
      "              ->  Partial GroupAggregate  (cost=168882.89..168883.31 rows=14 width=60) (actual time=1043.225..1045.536 rows=2 loops=3)\n",
      "                    Group Key: lineitem.l_shipmode\n",
      "                    ->  Sort  (cost=168882.89..168882.92 rows=14 width=108) (actual time=1040.517..1041.475 rows=10403 loops=3)\n",
      "                          Sort Key: lineitem.l_shipmode\n",
      "                          Sort Method: quicksort  Memory: 1307kB\n",
      "                          Worker 0:  Sort Method: quicksort  Memory: 1150kB\n",
      "                          Worker 1:  Sort Method: quicksort  Memory: 1134kB\n",
      "                          ->  Nested Loop  (cost=0.43..168882.62 rows=14 width=108) (actual time=16.737..1029.957 rows=10403 loops=3)\n",
      "                                ->  Parallel Seq Scan on lineitem  (cost=0.00..168764.39 rows=14 width=48) (actual time=16.514..911.724 rows=10403 loops=3)\n",
      "                                      Filter: ((l_shipmode = ANY ('{\"REG AIR\",TRUCK}'::bpchar[])) AND (l_commitdate < l_receiptdate) AND (l_shipdate < l_commitdate) AND (l_receiptdate >= '1996-01-01'::date) AND (l_receiptdate < '1997-01-01 00:00:00'::timestamp without time zone))\n",
      "                                      Rows Removed by Filter: 1990002\n",
      "                                ->  Index Scan using orders_pkey on orders  (cost=0.43..8.45 rows=1 width=68) (actual time=0.010..0.010 rows=1 loops=31208)\n",
      "                                      Index Cond: (o_orderkey = lineitem.l_orderkey)\n",
      "Planning Time: 0.335 ms\n",
      "JIT:\n",
      "  Functions: 43\n",
      "  Options: Inlining false, Optimization false, Expressions true, Deforming true\n",
      "  Timing: Generation 7.367 ms, Inlining 0.000 ms, Optimization 3.234 ms, Emission 62.200 ms, Total 72.800 ms\n",
      "Execution Time: 1091.843 ms\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "ALGORITMOS IDENTIFICADOS NO PLANO DE EXECUÇÃO:\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Algoritmos de Junção: Nested Loop\n",
      "Algoritmos de Varredura: Seq Scan, Index Scan\n",
      "Algoritmos de Ordenação: Sort\n",
      "Algoritmos de Agregação: GroupAggregate\n"
     ]
    }
   ],
   "source": [
    "host = \"localhost\"\n",
    "port = 5432\n",
    "user = \"postgres\"\n",
    "password = \"test123\"\n",
    "database = \"tpch\"\n",
    "filepath = \"query_root/perf_query_gen/\"\n",
    "\n",
    "conn = PGDBWithResults(host, port, database, user, password)\n",
    "\n",
    "# Definir algoritmos de junção e varredura comuns no PostgreSQL\n",
    "algoritmos_juncao = ['Nested Loop', 'Hash Join', 'Merge Join']\n",
    "algoritmos_varredura = ['Seq Scan', 'Index Scan', 'Index Only Scan', 'Bitmap Heap Scan', 'Bitmap Index Scan']\n",
    "algoritmos_ordenacao = ['Sort', 'Incremental Sort']\n",
    "algoritmos_agregacao = ['HashAggregate', 'GroupAggregate']\n",
    "\n",
    "for i in [1, 3, 5, 6, 7, 9, 10, 12]:\n",
    "    print(f\"\\n{'=' * 120}\")\n",
    "    print(f\"EXPLAIN ANALYZE - QUERY {i}\")\n",
    "    print(f\"{'=' * 120}\")\n",
    "    \n",
    "    # Ler a query original\n",
    "    with open(filepath + f\"{i}.sql\", 'r') as f:\n",
    "        original_query = f.read()\n",
    "    \n",
    "    # Adicionar EXPLAIN ANALYZE\n",
    "    explain_query = \"EXPLAIN ANALYZE \" + original_query\n",
    "    \n",
    "    start_time = datetime.datetime.now()\n",
    "    result = conn.executeQuery(explain_query)\n",
    "    end_time = datetime.datetime.now()\n",
    "    execution_time = end_time - start_time\n",
    "    \n",
    "    if 'error' in result:\n",
    "        print(f\"Erro no EXPLAIN ANALYZE {i}: {result['error']}\")\n",
    "    elif 'data' in result:\n",
    "        print(f\"\\nTempo de execução do EXPLAIN: {execution_time}\")\n",
    "        \n",
    "        # Coletar algoritmos utilizados\n",
    "        algoritmos_encontrados = {\n",
    "            'juncao': [],\n",
    "            'varredura': [],\n",
    "            'ordenacao': [],\n",
    "            'agregacao': [],\n",
    "            'outros': []\n",
    "        }\n",
    "        \n",
    "        print(f\"\\nPLANO DE EXECUÇÃO (EXPLAIN ANALYZE):\")\n",
    "        for idx, row in enumerate(result['data']):\n",
    "            plan_line = list(row.values())[0] if row else \"\"\n",
    "            print(f\"{plan_line}\")\n",
    "            \n",
    "            # Identificar algoritmos na linha do plano\n",
    "            for algoritmo in algoritmos_juncao:\n",
    "                if algoritmo in plan_line:\n",
    "                    if algoritmo not in algoritmos_encontrados['juncao']:\n",
    "                        algoritmos_encontrados['juncao'].append(algoritmo)\n",
    "            \n",
    "            for algoritmo in algoritmos_varredura:\n",
    "                if algoritmo in plan_line:\n",
    "                    if algoritmo not in algoritmos_encontrados['varredura']:\n",
    "                        algoritmos_encontrados['varredura'].append(algoritmo)\n",
    "            \n",
    "            for algoritmo in algoritmos_ordenacao:\n",
    "                if algoritmo in plan_line:\n",
    "                    if algoritmo not in algoritmos_encontrados['ordenacao']:\n",
    "                        algoritmos_encontrados['ordenacao'].append(algoritmo)\n",
    "            \n",
    "            for algoritmo in algoritmos_agregacao:\n",
    "                if algoritmo in plan_line:\n",
    "                    if algoritmo not in algoritmos_encontrados['agregacao']:\n",
    "                        algoritmos_encontrados['agregacao'].append(algoritmo)\n",
    "        \n",
    "        # Mostrar resumo dos algoritmos utilizados\n",
    "        print(f\"\\n{'─' * 80}\")\n",
    "        print(\"ALGORITMOS IDENTIFICADOS NO PLANO DE EXECUÇÃO:\")\n",
    "        print(f\"{'─' * 80}\")\n",
    "        \n",
    "        if algoritmos_encontrados['juncao']:\n",
    "            print(f\"Algoritmos de Junção: {', '.join(algoritmos_encontrados['juncao'])}\")\n",
    "        \n",
    "        if algoritmos_encontrados['varredura']:\n",
    "            print(f\"Algoritmos de Varredura: {', '.join(algoritmos_encontrados['varredura'])}\")\n",
    "        \n",
    "        if algoritmos_encontrados['ordenacao']:\n",
    "            print(f\"Algoritmos de Ordenação: {', '.join(algoritmos_encontrados['ordenacao'])}\")\n",
    "        \n",
    "        if algoritmos_encontrados['agregacao']:\n",
    "            print(f\"Algoritmos de Agregação: {', '.join(algoritmos_encontrados['agregacao'])}\")\n",
    "        \n",
    "        # Verificar se não foram encontrados algoritmos conhecidos\n",
    "        total_algoritmos = (len(algoritmos_encontrados['juncao']) + \n",
    "                          len(algoritmos_encontrados['varredura']) + \n",
    "                          len(algoritmos_encontrados['ordenacao']) + \n",
    "                          len(algoritmos_encontrados['agregacao']))\n",
    "        \n",
    "        if total_algoritmos == 0:\n",
    "            print(\"ℹNenhum algoritmo específico identificado (possivelmente plano simples)\")\n",
    "            \n",
    "    else:\n",
    "        print(f\"{result.get('message', 'Resultado inesperado')}\")\n",
    "        print(f\"Tempo: {execution_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf60578d",
   "metadata": {},
   "source": [
    "## Parte II\n",
    "Análise do comportamento dos índices das tabelas do SGBD através do exame das tabelas de estatísticas para consultas SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39478c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conectado ao PostgreSQL.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Configuração de conexão para a PARTE II\n",
    "DB_CONFIG_PARTE2 = {\n",
    "    \"dbname\": \"tpch\",\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"test123\",   \n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": 5432\n",
    "}\n",
    "\n",
    "conn_p2 = psycopg2.connect(**DB_CONFIG_PARTE2)\n",
    "cur_p2 = conn_p2.cursor()\n",
    "print(\"Conectado ao PostgreSQL.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8355f1ab",
   "metadata": {},
   "source": [
    "### Tarefa 5 – Preparação da Tabela Aleatória\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36c53abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabela t criada e populada com 100.000 tuplas.\n",
      "\n",
      "Primeiras 10 tuplas da tabela t (ordenadas por k):\n",
      "    k  v\n",
      "0   1  1\n",
      "1   2  3\n",
      "2   3  8\n",
      "3   4  8\n",
      "4   5  5\n",
      "5   6  2\n",
      "6   7  0\n",
      "7   8  0\n",
      "8   9  0\n",
      "9  10  0\n"
     ]
    }
   ],
   "source": [
    "cur_p2.execute(\"\"\"\n",
    "DROP TABLE IF EXISTS t;\n",
    "CREATE TABLE t (\n",
    "    k serial PRIMARY KEY,\n",
    "    v integer\n",
    ");\n",
    "\n",
    "INSERT INTO t(v)\n",
    "SELECT trunc(random() * 10)\n",
    "FROM generate_series(1,100000);\n",
    "\"\"\")\n",
    "conn_p2.commit()\n",
    "print(\"Tabela t criada e populada com 100.000 tuplas.\")\n",
    "\n",
    "cur_p2.execute(\"SELECT * FROM t ORDER BY k LIMIT 10;\")\n",
    "rows = cur_p2.fetchall()\n",
    "df_t10 = pd.DataFrame(rows, columns=[\"k\", \"v\"])\n",
    "print(\"\\nPrimeiras 10 tuplas da tabela t (ordenadas por k):\")\n",
    "print(df_t10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032afcdb",
   "metadata": {},
   "source": [
    "### Tarefa 6 – Páginas criadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ecd7976f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  relname  relpages  reltuples\n",
      "0       t         0       -1.0\n"
     ]
    }
   ],
   "source": [
    "cur_p2.execute(\"\"\"\n",
    "SELECT relname, relpages, reltuples\n",
    "FROM pg_class\n",
    "WHERE relname = 't';\n",
    "\"\"\")\n",
    "rows = cur_p2.fetchall()\n",
    "df_pgclass = pd.DataFrame(rows, columns=[\"relname\", \"relpages\", \"reltuples\"])\n",
    "print(df_pgclass)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133dffae",
   "metadata": {},
   "source": [
    "### Tarefa 7 – Blocos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d6ca43d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Estatísticas em pg_stats para tabela t:\n",
      "Empty DataFrame\n",
      "Columns: [schemaname, tablename, attname, inherited, null_frac, avg_width, n_distinct, most_common_vals, most_common_freqs, histogram_bounds, correlation, most_common_elems, most_common_elem_freqs, elem_count_histogram]\n",
      "Index: []\n",
      "\n",
      "Estatísticas resetadas com pg_stat_reset().\n"
     ]
    }
   ],
   "source": [
    "cur_p2.execute(\"SELECT pg_sleep(1);\")\n",
    "\n",
    "cur_p2.execute(\"\"\"\n",
    "SELECT *\n",
    "FROM pg_stats\n",
    "WHERE tablename = 't';\n",
    "\"\"\")\n",
    "cols = [desc[0] for desc in cur_p2.description]\n",
    "df_pgstats = pd.DataFrame(cur_p2.fetchall(), columns=cols)\n",
    "\n",
    "print(\"\\nEstatísticas em pg_stats para tabela t:\")\n",
    "print(df_pgstats)\n",
    "\n",
    "cur_p2.execute(\"SELECT pg_stat_reset();\")\n",
    "conn_p2.commit()\n",
    "print(\"\\nEstatísticas resetadas com pg_stat_reset().\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad6b99c",
   "metadata": {},
   "source": [
    "### Tarefa 8 – Índice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0627e950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo para criar índice idx_v (100k tuplas): 0.133247 s\n",
      "Tempo de consulta (v = 5) com 100k tuplas: 0.007123 s\n",
      "Tuplas retornadas: 9930\n",
      "\n",
      "Recriando tabela t com 1.000.000 tuplas...\n",
      "Tabela t populada com 1.000.000 de tuplas.\n",
      "Tempo para criar índice idx_v (1M tuplas): 0.917239 s\n",
      "Tempo de consulta (v = 5) com 1M tuplas: 0.124205 s\n",
      "Tuplas retornadas: 100695\n"
     ]
    }
   ],
   "source": [
    "# Índice e consulta com 100k tuplas\n",
    "inicio = time.time()\n",
    "cur_p2.execute(\"CREATE INDEX idx_v ON t(v);\")\n",
    "conn_p2.commit()\n",
    "fim = time.time()\n",
    "tempo_criacao_100k = fim - inicio\n",
    "print(f\"Tempo para criar índice idx_v (100k tuplas): {tempo_criacao_100k:.6f} s\")\n",
    "\n",
    "inicio = time.time()\n",
    "cur_p2.execute(\"SELECT * FROM t WHERE v = 5;\")\n",
    "rows = cur_p2.fetchall()\n",
    "fim = time.time()\n",
    "tempo_consulta_100k = fim - inicio\n",
    "print(f\"Tempo de consulta (v = 5) com 100k tuplas: {tempo_consulta_100k:.6f} s\")\n",
    "print(\"Tuplas retornadas:\", len(rows))\n",
    "\n",
    "# Recriar tabela t com 1.000.000 de tuplas\n",
    "print(\"\\nRecriando tabela t com 1.000.000 tuplas...\")\n",
    "\n",
    "cur_p2.execute(\"DROP TABLE IF EXISTS t;\")\n",
    "cur_p2.execute(\"\"\"\n",
    "CREATE TABLE t (\n",
    "    k serial PRIMARY KEY,\n",
    "    v integer\n",
    ");\n",
    "\"\"\")\n",
    "conn_p2.commit()\n",
    "\n",
    "cur_p2.execute(\"\"\"\n",
    "INSERT INTO t(v)\n",
    "SELECT trunc(random() * 10)\n",
    "FROM generate_series(1,1000000);\n",
    "\"\"\")\n",
    "conn_p2.commit()\n",
    "print(\"Tabela t populada com 1.000.000 de tuplas.\")\n",
    "\n",
    "inicio = time.time()\n",
    "cur_p2.execute(\"CREATE INDEX idx_v ON t(v);\")\n",
    "conn_p2.commit()\n",
    "fim = time.time()\n",
    "tempo_criacao_1m = fim - inicio\n",
    "print(f\"Tempo para criar índice idx_v (1M tuplas): {tempo_criacao_1m:.6f} s\")\n",
    "\n",
    "inicio = time.time()\n",
    "cur_p2.execute(\"SELECT * FROM t WHERE v = 5;\")\n",
    "rows = cur_p2.fetchall()\n",
    "fim = time.time()\n",
    "tempo_consulta_1m = fim - inicio\n",
    "print(f\"Tempo de consulta (v = 5) com 1M tuplas: {tempo_consulta_1m:.6f} s\")\n",
    "print(\"Tuplas retornadas:\", len(rows))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9830f6",
   "metadata": {},
   "source": [
    "- O tempo para criar o índice cresce aproximadamente de forma linear com o número de tuplas.\n",
    "\n",
    "- O índice acelera consultas para v = 5, mantendo tempo < 0,1s mesmo com 1 milhão de tuplas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fc1557",
   "metadata": {},
   "source": [
    "### Tarefa 9 – Fillfactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "111621ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados por fillfactor (índice ASC):\n",
      "   fillfactor  tempo_criacao  tempo_consulta\n",
      "0          60       0.908469        0.102965\n",
      "1          80       0.774314        0.114867\n",
      "2          90       0.787775        0.123920\n",
      "3         100       0.819310        0.095174\n"
     ]
    }
   ],
   "source": [
    "cur_p2.execute(\"DROP INDEX IF EXISTS idx_v;\")\n",
    "conn_p2.commit()\n",
    "\n",
    "fillfactors = [60, 80, 90, 100]\n",
    "resultados_ff = []\n",
    "\n",
    "for ff in fillfactors:\n",
    "    idx_name = f\"idx_v_ff{ff}\"\n",
    "    cur_p2.execute(f\"DROP INDEX IF EXISTS {idx_name};\")\n",
    "    conn_p2.commit()\n",
    "\n",
    "    inicio = time.time()\n",
    "    cur_p2.execute(f\"\"\"\n",
    "        CREATE INDEX {idx_name} ON t(v)\n",
    "        WITH (fillfactor = {ff});\n",
    "    \"\"\")\n",
    "    conn_p2.commit()\n",
    "    fim = time.time()\n",
    "    tempo_criacao = fim - inicio\n",
    "\n",
    "    inicio = time.time()\n",
    "    cur_p2.execute(\"SELECT * FROM t WHERE v = 5;\")\n",
    "    cur_p2.fetchall()\n",
    "    fim = time.time()\n",
    "    tempo_consulta = fim - inicio\n",
    "\n",
    "    resultados_ff.append([ff, tempo_criacao, tempo_consulta])\n",
    "\n",
    "df_fillfactor = pd.DataFrame(resultados_ff, columns=[\"fillfactor\", \"tempo_criacao\", \"tempo_consulta\"])\n",
    "print(\"\\nResultados por fillfactor (índice ASC):\")\n",
    "print(df_fillfactor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce676bb",
   "metadata": {},
   "source": [
    "Os resultados mostram que o fillfactor tem impacto mínimo no desempenho de consultas com igualdade (v = 5) em uma tabela estática. Isso ocorre porque o fillfactor afeta principalmente operações de escrita (inserções e atualizações) e não operações de leitura. Portanto, é esperado que todos os valores testados apresentem tempos muito semelhantes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c27f45",
   "metadata": {},
   "source": [
    "### Tarefa 10 – Índices DESC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5082219d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo criação índice descendente idx_v_desc: 0.862453 s\n",
      "Tempo consulta (v = 5) com índice descendente: 0.100775 s\n",
      "\n",
      "Resultados por fillfactor (índice DESC):\n",
      "   fillfactor  tempo_criacao  tempo_consulta\n",
      "0          60       1.045774        0.113597\n",
      "1          80       0.781081        0.100150\n",
      "2          90       0.803743        0.101465\n",
      "3         100       0.936104        0.098132\n",
      "\n",
      "Conexão da PARTE II encerrada.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cur_p2.execute(\"DROP INDEX IF EXISTS idx_v_desc;\")\n",
    "conn_p2.commit()\n",
    "\n",
    "inicio = time.time()\n",
    "cur_p2.execute(\"CREATE INDEX idx_v_desc ON t(v DESC NULLS FIRST);\")\n",
    "conn_p2.commit()\n",
    "fim = time.time()\n",
    "tempo_criacao_desc = fim - inicio\n",
    "print(f\"Tempo criação índice descendente idx_v_desc: {tempo_criacao_desc:.6f} s\")\n",
    "\n",
    "inicio = time.time()\n",
    "cur_p2.execute(\"SELECT * FROM t WHERE v = 5;\")\n",
    "cur_p2.fetchall()\n",
    "fim = time.time()\n",
    "tempo_consulta_desc = fim - inicio\n",
    "print(f\"Tempo consulta (v = 5) com índice descendente: {tempo_consulta_desc:.6f} s\")\n",
    "\n",
    "fillfactors = [60, 80, 90, 100]\n",
    "resultados_desc_ff = []\n",
    "\n",
    "for ff in fillfactors:\n",
    "    idx_name = f\"idx_v_desc_ff{ff}\"\n",
    "    cur_p2.execute(f\"DROP INDEX IF EXISTS {idx_name};\")\n",
    "    conn_p2.commit()\n",
    "\n",
    "    inicio = time.time()\n",
    "    cur_p2.execute(f\"\"\"\n",
    "        CREATE INDEX {idx_name} ON t(v DESC NULLS FIRST)\n",
    "        WITH (fillfactor = {ff});\n",
    "    \"\"\")\n",
    "    conn_p2.commit()\n",
    "    fim = time.time()\n",
    "    tempo_criacao = fim - inicio\n",
    "\n",
    "    inicio = time.time()\n",
    "    cur_p2.execute(\"SELECT * FROM t WHERE v = 5;\")\n",
    "    cur_p2.fetchall()\n",
    "    fim = time.time()\n",
    "    tempo_consulta = fim - inicio\n",
    "\n",
    "    resultados_desc_ff.append([ff, tempo_criacao, tempo_consulta])\n",
    "\n",
    "df_desc_fillfactor = pd.DataFrame(resultados_desc_ff, columns=[\"fillfactor\", \"tempo_criacao\", \"tempo_consulta\"])\n",
    "print(\"\\nResultados por fillfactor (índice DESC):\")\n",
    "print(df_desc_fillfactor)\n",
    "\n",
    "# Fechar conexão da Parte II\n",
    "cur_p2.close()\n",
    "conn_p2.close()\n",
    "print(\"\\nConexão da PARTE II encerrada.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e280fa28",
   "metadata": {},
   "source": [
    "- Índices descendentes apresentam desempenho muito semelhante aos índices em ordem padrão (ASC) para consultas por igualdade (v = 5).\n",
    "\n",
    "- A escolha entre ASC e DESC é mais importante quando o plano de execução precisa retornar dados ordenados por v, especialmente com ORDER BY v DESC LIMIT n.\n",
    "\n",
    "- As variações de fillfactor (60, 80, 90, 100) nos índices descendentes não alteraram de forma significativa o tempo de consulta, o que confirma que:\n",
    "\n",
    "    - fillfactor impacta principalmente operações de escrita,\n",
    "\n",
    "    - enquanto consultas de leitura simples são pouco sensíveis a essa configuração em tabelas estáticas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb6e3df",
   "metadata": {},
   "source": [
    "## Parte III"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a0b25a",
   "metadata": {},
   "source": [
    "O objetivo desta parte do trabalho é estudar o comportamento dos otimizadores de consulta dos SGBDs através do exame e análise dos planos de execução para consultas SQL sobre tabelas que serão fornecidos. Será bastante utilizado o comando EXPLAIN ANALYZE, que permite visualizar todas as etapas envolvidas no processamento de uma consulta. Usaremos para isso a tabela “movies”."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ed4b60",
   "metadata": {},
   "source": [
    "### Tarefa 11 – Preparaçao e Verificaçao do ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c5bfc4e",
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conectado ao banco tpch!\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "\n",
    "DB_CONFIG = {\n",
    "    \"dbname\": \"tpch\",\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"test123\",\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": 5432\n",
    "}\n",
    "\n",
    "conn = psycopg2.connect(**DB_CONFIG)\n",
    "conn.autocommit = True\n",
    "cur = conn.cursor()\n",
    "\n",
    "print(\"Conectado ao banco tpch!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23559252",
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie.sql executado com sucesso!\n",
      "Extensão pgstattuple verificada!\n"
     ]
    }
   ],
   "source": [
    "caminho = '/home/desktoop2/repos/Banco-de-Dados-2025-2/Trabalho 3/tpch4pgsql/movie.sql'\n",
    "\n",
    "with open(caminho, \"r\", encoding=\"utf-8\") as f:\n",
    "    sql = f.read()\n",
    "\n",
    "cur.execute(sql)\n",
    "\n",
    "print(\"movie.sql executado com sucesso!\")\n",
    "\n",
    "cur.execute(\"CREATE EXTENSION IF NOT EXISTS pgstattuple;\")\n",
    "print(\"Extensão pgstattuple verificada!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "87a8d163",
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "WITH info AS (\n",
    "    SELECT\n",
    "        ic.relname AS index_name,\n",
    "        tc.relname AS table_name,\n",
    "        pg_relation_size(ic.oid) / 8192 AS total_blocks,\n",
    "        st.n_live_tup AS num_rows,\n",
    "        i.indrelid,\n",
    "        i.indexrelid\n",
    "    FROM pg_index i\n",
    "    JOIN pg_class ic ON ic.oid = i.indexrelid\n",
    "    JOIN pg_class tc ON tc.oid = i.indrelid\n",
    "    JOIN pg_stat_all_tables st ON st.relname = tc.relname\n",
    "    WHERE tc.relname = 'movie'\n",
    ")\n",
    "SELECT\n",
    "    index_name,\n",
    "    table_name,\n",
    "    total_blocks AS blocos_totais,\n",
    "    num_rows AS num_chaves,\n",
    "    total_blocks - 1 AS blocos_folha,     -- aproximação padrão\n",
    "    (num_rows::float / (total_blocks - 1)) AS media_chaves_por_bloco\n",
    "FROM info\n",
    "ORDER BY index_name;\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9dae4178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Índice</th>\n",
       "      <th>Tabela</th>\n",
       "      <th>Blocos totais</th>\n",
       "      <th>Nº chaves</th>\n",
       "      <th>Blocos folha</th>\n",
       "      <th>Média chaves/bloco</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>movie_key</td>\n",
       "      <td>movie</td>\n",
       "      <td>7</td>\n",
       "      <td>1844</td>\n",
       "      <td>6</td>\n",
       "      <td>307.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>movie_title</td>\n",
       "      <td>movie</td>\n",
       "      <td>12</td>\n",
       "      <td>1844</td>\n",
       "      <td>11</td>\n",
       "      <td>167.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>movie_votes</td>\n",
       "      <td>movie</td>\n",
       "      <td>11</td>\n",
       "      <td>1844</td>\n",
       "      <td>10</td>\n",
       "      <td>184.400000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Índice Tabela  Blocos totais  Nº chaves  Blocos folha  \\\n",
       "0    movie_key  movie              7       1844             6   \n",
       "1  movie_title  movie             12       1844            11   \n",
       "2  movie_votes  movie             11       1844            10   \n",
       "\n",
       "   Média chaves/bloco  \n",
       "0          307.333333  \n",
       "1          167.636364  \n",
       "2          184.400000  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute(query)\n",
    "dados = cur.fetchall()\n",
    "\n",
    "df_idx = pd.DataFrame(dados, columns=[\n",
    "    \"Índice\", \"Tabela\", \"Blocos totais\", \"Nº chaves\",\n",
    "    \"Blocos folha\", \"Média chaves/bloco\"\n",
    "])\n",
    "\n",
    "df_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aba85ee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'movie_title': 1833, 'movie_votes': 1481}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distinct = {\n",
    "    \"movie_title\": \"SELECT COUNT(DISTINCT title) FROM movie;\",\n",
    "    \"movie_votes\": \"SELECT COUNT(DISTINCT votes) FROM movie;\"\n",
    "}\n",
    "\n",
    "distinct_counts = {}\n",
    "for idx, q in distinct.items():\n",
    "    cur.execute(q)\n",
    "    distinct_counts[idx] = cur.fetchone()[0]\n",
    "\n",
    "distinct_counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe86689",
   "metadata": {},
   "source": [
    "### Tarefa 12 – Consultas por intervalo e índices secundários\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8266f15e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consulta seletiva (<10 tuplas):\n",
      "\n",
      "Index Scan using movie_votes on movie  (cost=0.28..8.30 rows=1 width=30) (actual time=0.010..0.012 rows=1 loops=1)\n",
      "  Index Cond: ((votes >= 53560) AND (votes <= 53570))\n",
      "Planning Time: 0.195 ms\n",
      "Execution Time: 0.034 ms\n",
      "\n",
      "Consulta ampla (>80% das tuplas):\n",
      "\n",
      "Index Scan using movie_votes on movie  (cost=0.28..36.81 rows=659 width=30) (actual time=0.020..0.334 rows=661 loops=1)\n",
      "  Index Cond: (votes > 3000)\n",
      "Planning Time: 0.109 ms\n",
      "Execution Time: 0.416 ms\n"
     ]
    }
   ],
   "source": [
    "# Consulta seletiva (<10 tuplas)\n",
    "cur.execute(\"\"\"\n",
    "EXPLAIN ANALYZE\n",
    "SELECT *\n",
    "FROM movie\n",
    "WHERE votes BETWEEN 53560 AND 53570;\n",
    "\"\"\")\n",
    "\n",
    "print(\"Consulta seletiva (<10 tuplas):\\n\")\n",
    "for r in cur.fetchall():\n",
    "    print(r[0])\n",
    "\n",
    "\n",
    "# Consulta ampla (>80% das tuplas)\n",
    "cur.execute(\"\"\"\n",
    "EXPLAIN ANALYZE\n",
    "SELECT *\n",
    "FROM movie\n",
    "WHERE votes > 3000;\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nConsulta ampla (>80% das tuplas):\\n\")\n",
    "for r in cur.fetchall():\n",
    "    print(r[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb871388",
   "metadata": {},
   "source": [
    "### Tarefa 13 – Comparações de operadores de agregação.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f2c463e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consulta A — MAX():\n",
      "\n",
      "Index Scan using movie_votes on movie  (cost=0.61..35.37 rows=615 width=16) (actual time=0.029..0.030 rows=1 loops=1)\n",
      "  Index Cond: (votes >= $1)\n",
      "  InitPlan 2 (returns $1)\n",
      "    ->  Result  (cost=0.32..0.33 rows=1 width=4) (actual time=0.019..0.020 rows=1 loops=1)\n",
      "          InitPlan 1 (returns $0)\n",
      "            ->  Limit  (cost=0.28..0.32 rows=1 width=4) (actual time=0.017..0.017 rows=1 loops=1)\n",
      "                  ->  Index Only Scan Backward using movie_votes on movie movie_1  (cost=0.28..76.55 rows=1844 width=4) (actual time=0.016..0.016 rows=1 loops=1)\n",
      "                        Index Cond: (votes IS NOT NULL)\n",
      "                        Heap Fetches: 0\n",
      "Planning Time: 0.306 ms\n",
      "Execution Time: 0.059 ms\n",
      "\n",
      "Consulta B — ALL:\n",
      "\n",
      "Seq Scan on movie  (cost=0.00..43620.99 rows=922 width=16) (actual time=1.297..2.293 rows=1 loops=1)\n",
      "  Filter: (SubPlan 1)\n",
      "  Rows Removed by Filter: 1843\n",
      "  SubPlan 1\n",
      "    ->  Materialize  (cost=0.00..42.66 rows=1844 width=4) (actual time=0.000..0.001 rows=2 loops=1844)\n",
      "          ->  Seq Scan on movie movie_1  (cost=0.00..33.44 rows=1844 width=4) (actual time=0.003..0.435 rows=1844 loops=1)\n",
      "Planning Time: 0.111 ms\n",
      "Execution Time: 2.329 ms\n"
     ]
    }
   ],
   "source": [
    "# EXPLAIN ANALYZE da consulta A (com MAX)\n",
    "cur.execute(\"\"\"\n",
    "EXPLAIN ANALYZE\n",
    "SELECT title \n",
    "FROM movie\n",
    "WHERE votes >= (SELECT MAX(votes) FROM movie);\n",
    "\"\"\")\n",
    "print(\"Consulta A — MAX():\\n\")\n",
    "for r in cur.fetchall():\n",
    "    print(r[0])\n",
    "\n",
    "\n",
    "# EXPLAIN ANALYZE da consulta B (com ALL)\n",
    "cur.execute(\"\"\"\n",
    "EXPLAIN ANALYZE\n",
    "SELECT title \n",
    "FROM movie\n",
    "WHERE votes >= ALL (SELECT votes FROM movie);\n",
    "\"\"\")\n",
    "print(\"\\nConsulta B — ALL:\\n\")\n",
    "for r in cur.fetchall():\n",
    "    print(r[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca45499",
   "metadata": {},
   "source": [
    "### Tarefa 14 – Consultas com Junção e Seleção\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "564c825c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consulta A — Subconsulta:\n",
      "\n",
      "Index Scan using movie_votes on movie  (cost=8.57..43.34 rows=615 width=16) (actual time=0.023..0.024 rows=0 loops=1)\n",
      "  Index Cond: (votes > $0)\n",
      "  InitPlan 1 (returns $0)\n",
      "    ->  Index Scan using movie_title on movie movie_1  (cost=0.28..8.29 rows=1 width=4) (actual time=0.014..0.015 rows=1 loops=1)\n",
      "          Index Cond: ((title)::text = 'Star Wars'::text)\n",
      "Planning Time: 0.120 ms\n",
      "Execution Time: 0.044 ms\n",
      "\n",
      "Consulta B — Self Join:\n",
      "\n",
      "Nested Loop  (cost=0.56..49.49 rows=615 width=16) (actual time=0.022..0.023 rows=0 loops=1)\n",
      "  ->  Index Scan using movie_title on movie m2  (cost=0.28..8.29 rows=1 width=4) (actual time=0.014..0.015 rows=1 loops=1)\n",
      "        Index Cond: ((title)::text = 'Star Wars'::text)\n",
      "  ->  Index Scan using movie_votes on movie m1  (cost=0.28..35.04 rows=615 width=20) (actual time=0.005..0.005 rows=0 loops=1)\n",
      "        Index Cond: (votes > m2.votes)\n",
      "Planning Time: 0.164 ms\n",
      "Execution Time: 0.045 ms\n"
     ]
    }
   ],
   "source": [
    "# Consulta A: subconsulta\n",
    "cur.execute(\"\"\"\n",
    "EXPLAIN ANALYZE\n",
    "SELECT title \n",
    "FROM movie \n",
    "WHERE votes > (SELECT votes FROM movie WHERE title = 'Star Wars');\n",
    "\"\"\")\n",
    "\n",
    "print(\"Consulta A — Subconsulta:\\n\")\n",
    "for r in cur.fetchall():\n",
    "    print(r[0])\n",
    "\n",
    "\n",
    "# Consulta B: junção\n",
    "cur.execute(\"\"\"\n",
    "EXPLAIN ANALYZE\n",
    "SELECT m1.title\n",
    "FROM movie m1, movie m2\n",
    "WHERE m1.votes > m2.votes\n",
    "  AND m2.title = 'Star Wars';\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nConsulta B — Self Join:\\n\")\n",
    "for r in cur.fetchall():\n",
    "    print(r[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f62b2d",
   "metadata": {},
   "source": [
    "### Tarefa 15  – Casamento de Strings e Índices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "14904f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consulta 1 — LIKE 'I%':\n",
      "\n",
      "Seq Scan on movie  (cost=0.00..38.05 rows=18 width=16)\n",
      "  Filter: ((title)::text ~~ 'I%'::text)\n",
      "\n",
      "Consulta 2 — SUBSTR(title,1,1) = 'I':\n",
      "\n",
      "Seq Scan on movie  (cost=0.00..42.66 rows=9 width=16)\n",
      "  Filter: (substr((title)::text, 1, 1) = 'I'::text)\n",
      "\n",
      "Consulta 3 — LIKE '%A':\n",
      "\n",
      "Seq Scan on movie  (cost=0.00..38.05 rows=18 width=16)\n",
      "  Filter: ((title)::text ~~ '%A'::text)\n"
     ]
    }
   ],
   "source": [
    "# LIKE 'I%'\n",
    "cur.execute(\"\"\"\n",
    "EXPLAIN\n",
    "SELECT title \n",
    "FROM movie \n",
    "WHERE title LIKE 'I%';\n",
    "\"\"\")\n",
    "print(\"Consulta 1 — LIKE 'I%':\\n\")\n",
    "for r in cur.fetchall():\n",
    "    print(r[0])\n",
    "\n",
    "\n",
    "# SUBSTR(title,1,1) = 'I'\n",
    "cur.execute(\"\"\"\n",
    "EXPLAIN\n",
    "SELECT title\n",
    "FROM movie\n",
    "WHERE substr(title, 1, 1) = 'I';\n",
    "\"\"\")\n",
    "print(\"\\nConsulta 2 — SUBSTR(title,1,1) = 'I':\\n\")\n",
    "for r in cur.fetchall():\n",
    "    print(r[0])\n",
    "\n",
    "\n",
    "# LIKE '%A'\n",
    "cur.execute(\"\"\"\n",
    "EXPLAIN\n",
    "SELECT title \n",
    "FROM movie \n",
    "WHERE title LIKE '%A';\n",
    "\"\"\")\n",
    "print(\"\\nConsulta 3 — LIKE '%A':\\n\")\n",
    "for r in cur.fetchall():\n",
    "    print(r[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62468bcb",
   "metadata": {},
   "source": [
    "### Tarefa 16 – Verificação da hipótese de distribuição uniforme na estimativa de seletividade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6177efd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consulta 1 — votes < 1000:\n",
      "\n",
      "Index Scan using movie_votes on movie  (cost=0.28..20.02 rows=328 width=16)\n",
      "  Index Cond: (votes < 1000)\n",
      "\n",
      "Consulta 2 — votes > 40000:\n",
      "\n",
      "Index Scan using movie_votes on movie  (cost=0.28..8.42 rows=8 width=16)\n",
      "  Index Cond: (votes > 40000)\n"
     ]
    }
   ],
   "source": [
    "# Consulta 1 — votes < 1000\n",
    "cur.execute(\"\"\"\n",
    "EXPLAIN\n",
    "SELECT title\n",
    "FROM movie\n",
    "WHERE votes < 1000;\n",
    "\"\"\")\n",
    "print(\"Consulta 1 — votes < 1000:\\n\")\n",
    "for r in cur.fetchall():\n",
    "    print(r[0])\n",
    "\n",
    "\n",
    "# Consulta 2 — votes > 40000\n",
    "cur.execute(\"\"\"\n",
    "EXPLAIN\n",
    "SELECT title\n",
    "FROM movie\n",
    "WHERE votes > 40000;\n",
    "\"\"\")\n",
    "print(\"\\nConsulta 2 — votes > 40000:\\n\")\n",
    "for r in cur.fetchall():\n",
    "    print(r[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c6df6d",
   "metadata": {},
   "source": [
    "## Parte IV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a530dde",
   "metadata": {},
   "source": [
    "O objetivo desta parte do trabalho é experimentar estratégias para utilização de transações e níveis de isolamento em SGBDs relacionais. As tarefas envolvem uma simulação de um sistema de reservas de passagem áreas. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b1f50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import time\n",
    "import random\n",
    "import threading\n",
    "\n",
    "DB_CONFIG = {\n",
    "    \"dbname\": \"tpch\",\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"test123\",\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": 5432\n",
    "}\n",
    "\n",
    "def reset_db():\n",
    "    conn = psycopg2.connect(**DB_CONFIG)\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    cur.execute(\"DROP TABLE IF EXISTS assentos;\")\n",
    "    cur.execute(\"\"\"\n",
    "        CREATE TABLE assentos(\n",
    "            num_voo INT PRIMARY KEY,\n",
    "            disp BOOLEAN\n",
    "        );\n",
    "    \"\"\")\n",
    "\n",
    "    # 200 assentos inicialmente livres\n",
    "    cur.executemany(\"INSERT INTO assentos VALUES (%s, true);\", [(i,) for i in range(1, 201)])\n",
    "\n",
    "    conn.commit()\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "\n",
    "reset_db()\n",
    "print(\"Tabela assentos pronta.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1252fc44",
   "metadata": {},
   "source": [
    "### Tarefa 17 – Código das Versões A e B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bf2782",
   "metadata": {},
   "source": [
    "Versão A - Uma única transação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f314f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reserva_versaoA(isolation_level):\n",
    "\n",
    "    conn = psycopg2.connect(**DB_CONFIG)\n",
    "    conn.set_session(isolation_level=isolation_level)\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    tentativas = 0\n",
    "\n",
    "    while True:\n",
    "        tentativas += 1\n",
    "        try:\n",
    "            # Passo 1 — escolher 1 assento livre e BLOQUEAR apenas ele\n",
    "            cur.execute(\"\"\"\n",
    "                SELECT num_voo \n",
    "                FROM assentos \n",
    "                WHERE disp = true \n",
    "                ORDER BY random()\n",
    "                LIMIT 1\n",
    "                FOR UPDATE;\n",
    "            \"\"\")\n",
    "            row = cur.fetchone()\n",
    "\n",
    "            # Nenhum assento livre → fim\n",
    "            if not row:\n",
    "                conn.rollback()\n",
    "                break\n",
    "\n",
    "            escolhido = row[0]\n",
    "\n",
    "            # Passo 2 — espera de 1s (cliente escolhendo)\n",
    "            time.sleep(1)\n",
    "\n",
    "            # Passo 3 — marcar como ocupado\n",
    "            cur.execute(\"\"\"\n",
    "                UPDATE assentos \n",
    "                SET disp = false \n",
    "                WHERE num_voo = %s;\n",
    "            \"\"\", (escolhido,))\n",
    "\n",
    "            conn.commit()\n",
    "            break  # reserva feita com sucesso\n",
    "\n",
    "        except psycopg2.errors.SerializationFailure:\n",
    "            # conflitos serializáveis → tentar de novo\n",
    "            conn.rollback()\n",
    "            continue\n",
    "\n",
    "        except psycopg2.Error as e:\n",
    "            # erros inesperados devem ser reportados\n",
    "            conn.rollback()\n",
    "            print(\"Erro inesperado na versão A:\", e)\n",
    "            break\n",
    "\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    return tentativas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48836f96",
   "metadata": {},
   "source": [
    "Versão b - Duas transações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05728698",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reserva_versaoB(isolation_level):\n",
    "\n",
    "    tentativas = 0\n",
    "\n",
    "    while True:\n",
    "        tentativas += 1\n",
    "\n",
    "        try:\n",
    "            # ================================\n",
    "            # TRANSAÇÃO 1: obter 1 assento livre\n",
    "            # ================================\n",
    "            conn1 = psycopg2.connect(**DB_CONFIG)\n",
    "            conn1.set_session(isolation_level=isolation_level)\n",
    "            cur1 = conn1.cursor()\n",
    "\n",
    "            cur1.execute(\"\"\"\n",
    "                SELECT num_voo \n",
    "                FROM assentos \n",
    "                WHERE disp = true \n",
    "                ORDER BY random()\n",
    "                LIMIT 1;\n",
    "            \"\"\")\n",
    "\n",
    "            row = cur1.fetchone()\n",
    "\n",
    "            if not row:\n",
    "                conn1.commit()\n",
    "                conn1.close()\n",
    "                break  # nenhum assento disponível\n",
    "\n",
    "            escolhido = row[0]\n",
    "\n",
    "            conn1.commit()\n",
    "            conn1.close()\n",
    "\n",
    "            # ================================\n",
    "            # PASSO 2 — escolha do cliente\n",
    "            # ================================\n",
    "            time.sleep(1)\n",
    "\n",
    "            # ================================\n",
    "            # TRANSAÇÃO 2: tentar reservar\n",
    "            # ================================\n",
    "            conn2 = psycopg2.connect(**DB_CONFIG)\n",
    "            conn2.set_session(isolation_level=isolation_level)\n",
    "            cur2 = conn2.cursor()\n",
    "\n",
    "            cur2.execute(\"\"\"\n",
    "                UPDATE assentos\n",
    "                SET disp = false\n",
    "                WHERE num_voo = %s AND disp = true;\n",
    "            \"\"\", (escolhido,))\n",
    "\n",
    "            if cur2.rowcount == 1:\n",
    "                conn2.commit()\n",
    "                conn2.close()\n",
    "                break  # reserva concluída\n",
    "            else:\n",
    "                conn2.rollback()\n",
    "                conn2.close()\n",
    "                continue  # alguém já pegou → tentar novamente\n",
    "\n",
    "        except psycopg2.errors.SerializationFailure:\n",
    "            # conflito serializável → repetir tentativa\n",
    "            continue\n",
    "\n",
    "        except Exception as e:\n",
    "            # erro inesperado → reportar e quebrar\n",
    "            print(\"Erro inesperado na versão B:\", e)\n",
    "            break\n",
    "\n",
    "    return tentativas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd4b561",
   "metadata": {},
   "source": [
    "### Tarefa 18 – Executar experimentos e gerar gráficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac39de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import threading\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# k usados no experimento\n",
    "k_values = [1, 2, 4, 6, 8, 10]\n",
    "\n",
    "# estrutura para armazenar os tempos de cada experimento\n",
    "resultados = {\n",
    "    \"A_READ_COMMITTED\": [],\n",
    "    \"A_SERIALIZABLE\": [],\n",
    "    \"B_READ_COMMITTED\": [],\n",
    "    \"B_SERIALIZABLE\": []\n",
    "}\n",
    "\n",
    "estatisticas_tentativas = []\n",
    "\n",
    "def executar_experimento(k, versao_func, isolation_level, num_clientes=200):\n",
    "    \"\"\"\n",
    "    Executa um experimento com:\n",
    "    - k threads (agentes de viagem)\n",
    "    - num_clientes clientes (default = 200)\n",
    "    - versao_func: reserva_versaoA ou reserva_versaoB\n",
    "    - isolation_level: 'READ COMMITTED' ou 'SERIALIZABLE'\n",
    "\n",
    "    Retorna:\n",
    "        tempo_total (float),\n",
    "        tentativas_total (lista de tentativas por cliente),\n",
    "        estatisticas (dict com Min, Max, Média)\n",
    "    \"\"\"\n",
    "\n",
    "    # Começa sempre com a tabela de 200 assentos livres\n",
    "    reset_db()\n",
    "\n",
    "    inicio = time.time()\n",
    "    tentativas_total = []\n",
    "\n",
    "    contador = {\"cliente\": 0}\n",
    "    lock = threading.Lock()\n",
    "\n",
    "    def worker():\n",
    "        while True:\n",
    "            # pegar \"um cliente\" para esta thread\n",
    "            with lock:\n",
    "                if contador[\"cliente\"] >= num_clientes:\n",
    "                    return\n",
    "                contador[\"cliente\"] += 1\n",
    "\n",
    "            # atende um cliente (uma reserva completa)\n",
    "            tentativas = versao_func(isolation_level)\n",
    "            tentativas_total.append(tentativas)\n",
    "\n",
    "    # cria k threads/agentes\n",
    "    threads = [threading.Thread(target=worker) for _ in range(k)]\n",
    "\n",
    "    # inicia e aguarda todas\n",
    "    for t in threads:\n",
    "        t.start()\n",
    "    for t in threads:\n",
    "        t.join()\n",
    "\n",
    "    tempo_total = time.time() - inicio\n",
    "\n",
    "    # ---- estatísticas das tentativas ----\n",
    "    arr = np.array(tentativas_total)\n",
    "    estatisticas = {\n",
    "        \"Min\": arr.min(),\n",
    "        \"Max\": arr.max(),\n",
    "        \"Média\": arr.mean()\n",
    "    }\n",
    "\n",
    "    return tempo_total, tentativas_total, estatisticas\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffa8045",
   "metadata": {},
   "source": [
    "Executar Experimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab3752a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in k_values:\n",
    "    # Versão A - Read Committed\n",
    "    t, tent, stats = executar_experimento(k, reserva_versaoA, \"READ COMMITTED\")\n",
    "    resultados[\"A_READ_COMMITTED\"].append(t)\n",
    "\n",
    "    estatisticas_tentativas.append({\n",
    "        \"k\": k,\n",
    "        \"Versão\": \"A\",\n",
    "        \"Isolamento\": \"READ COMMITTED\",\n",
    "        \"Min\": stats[\"Min\"],\n",
    "        \"Max\": stats[\"Max\"],\n",
    "        \"Média\": stats[\"Média\"]\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044a253d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in k_values:\n",
    "    # Versão A - Serializable\n",
    "    t, tent, stats = executar_experimento(k, reserva_versaoA, \"SERIALIZABLE\")\n",
    "    resultados[\"A_SERIALIZABLE\"].append(t)\n",
    "\n",
    "    estatisticas_tentativas.append({\n",
    "        \"k\": k,\n",
    "        \"Versão\": \"A\",\n",
    "        \"Isolamento\": \"SERIALIZABLE\",\n",
    "        \"Min\": stats[\"Min\"],\n",
    "        \"Max\": stats[\"Max\"],\n",
    "        \"Média\": stats[\"Média\"]\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0521b861",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in k_values:\n",
    "    # Versão B - Read Committed\n",
    "    t, tent, stats = executar_experimento(k, reserva_versaoB, \"READ COMMITTED\")\n",
    "    resultados[\"B_READ_COMMITTED\"].append(t)\n",
    "\n",
    "    estatisticas_tentativas.append({\n",
    "        \"k\": k,\n",
    "        \"Versão\": \"B\",\n",
    "        \"Isolamento\": \"READ COMMITTED\",\n",
    "        \"Min\": stats[\"Min\"],\n",
    "        \"Max\": stats[\"Max\"],\n",
    "        \"Média\": stats[\"Média\"]\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2350d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in k_values:\n",
    "    # Versão B - Serializable\n",
    "    t, tent, stats = executar_experimento(k, reserva_versaoB, \"SERIALIZABLE\")\n",
    "    resultados[\"B_SERIALIZABLE\"].append(t)\n",
    "\n",
    "    estatisticas_tentativas.append({\n",
    "        \"k\": k,\n",
    "        \"Versão\": \"B\",\n",
    "        \"Isolamento\": \"SERIALIZABLE\",\n",
    "        \"Min\": stats[\"Min\"],\n",
    "        \"Max\": stats[\"Max\"],\n",
    "        \"Média\": stats[\"Média\"]\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947726c0",
   "metadata": {},
   "source": [
    "Gerar Gráficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835209e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerar_grafico(nome, valores, titulo):\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.plot(k_values, valores, marker='o')\n",
    "    plt.xlabel(\"Número de agentes (k)\")\n",
    "    plt.ylabel(\"Tempo total (s)\")\n",
    "    plt.title(titulo)\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Range fixo para facilitar comparação entre gráficos \n",
    "    plt.ylim(0, 300)  \n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "gerar_grafico(\n",
    "    \"A_READ_COMMITTED\",\n",
    "    resultados[\"A_READ_COMMITTED\"],\n",
    "    \"Versão A – Read Committed\"\n",
    ")\n",
    "\n",
    "gerar_grafico(\n",
    "    \"A_SERIALIZABLE\",\n",
    "    resultados[\"A_SERIALIZABLE\"],\n",
    "    \"Versão A – Serializable\"\n",
    ")\n",
    "\n",
    "gerar_grafico(\n",
    "    \"B_READ_COMMITTED\",\n",
    "    resultados[\"B_READ_COMMITTED\"],\n",
    "    \"Versão B – Read Committed\"\n",
    ")\n",
    "\n",
    "gerar_grafico(\n",
    "    \"B_SERIALIZABLE\",\n",
    "    resultados[\"B_SERIALIZABLE\"],\n",
    "    \"Versão B – Serializable\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ea69ca",
   "metadata": {},
   "source": [
    "### Tarefa 19 — Tabela de tentativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549d1016",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Criar DataFrame final\n",
    "df_tentativas = pd.DataFrame(estatisticas_tentativas)\n",
    "\n",
    "# Ordenar \n",
    "df_tentativas = df_tentativas.sort_values(by=[\"Versão\", \"Isolamento\", \"k\"])\n",
    "\n",
    "df_tentativas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f3efc7",
   "metadata": {},
   "source": [
    "### Tarefa 20 - Análise dos Resultados\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabed156",
   "metadata": {},
   "source": [
    "1. Versão A — Read Committed\n",
    "\n",
    "Na versão A com Read Committed, todos os clientes concluíram a reserva sempre na primeira tentativa.\n",
    "\n",
    "(Min = Max = Média = 1)\n",
    "\n",
    "Isso ocorre porque:\n",
    "\n",
    "- A leitura, a espera de 1 segundo e a escrita são executadas dentro de uma única transação.\n",
    "\n",
    "- No nível Read Committed, a leitura não é bloqueada e o SGBD não precisa garantir serialização global.\n",
    "\n",
    "- Conflitos reais só acontecem na escrita, e a chance de dois agentes reservarem o mesmo assento simultaneamente é baixa.\n",
    "\n",
    "*Conclusão*: desempenho estável, sem retrabalho e tempos compatíveis com o aumento de k.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36605ec",
   "metadata": {},
   "source": [
    "2. Versão A — Serializable\n",
    "\n",
    "Este foi o cenário mais custoso da simulação. O número de tentativas aumentou significativamente conforme k cresceu, chegando a até 8 retries.\n",
    "\n",
    "Motivos:\n",
    "\n",
    "- O nível Serializable exige que a transação inteira seja equivalente a uma execução isolada.\n",
    "\n",
    "- A versão A mantém a transação aberta durante o tempo de espera de 1 segundo, aumentando a janela crítica.\n",
    "\n",
    "- Vários agentes leem o mesmo estado dos assentos e tentam reservar posições semelhantes.\n",
    "\n",
    "- O PostgreSQL detecta conflitos de serialização (como phantom reads e write-write conflicts) e aborta transações, obrigando novas tentativas.\n",
    "\n",
    "*Conclusão:* alta contenção, muitos abortos de transação e pior desempenho entre todas as combinações."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ced971",
   "metadata": {},
   "source": [
    "3. Versão B — Read Committed\n",
    "\n",
    "A versão B apresentou apenas uma tentativa por cliente em todos os valores de k.\n",
    "\n",
    "Isso acontece porque:\n",
    "\n",
    "- A leitura e a escrita acontecem em transações separadas, ambas muito curtas.\n",
    "\n",
    "- O tempo de espera de 1 segundo ocorre fora de qualquer transação, reduzindo drasticamente a chance de conflito.\n",
    "\n",
    "- A escrita é rápida o suficiente para não gerar bloqueios significativos.\n",
    "\n",
    "*Conclusão:* excelente desempenho e nenhuma tentativa extra, mesmo com alta concorrência."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7981f0fa",
   "metadata": {},
   "source": [
    "4. Versão B — Serializable\n",
    "\n",
    "Mesmo sob Serializable, a versão B manteve Min = Max = Média = 1.\n",
    "Ou seja, a serialização não gerou overhead significativo.\n",
    "\n",
    "Razões:\n",
    "\n",
    "- Como a transação de escrita é extremamente curta, as chances de conflito são mínimas.\n",
    "\n",
    "- A separação entre leitura e escrita impede phantoms e reduz o risco de abortos.\n",
    "\n",
    "*Conclusão:* comportamento extremamente eficiente, mostrando que a versão B é robusta mesmo no nível de isolamento mais forte."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
